# Content
- [Attributes](https://github.com/vanikk06/Machine-Learning/tree/master/Data#attributes)
- [Symmetric vs. Skewed Data](https://github.com/vanikk06/Machine-Learning/tree/master/Data#symmetric-vs-skewed-data)
- [Basic Statistical Descriptions](https://github.com/vanikk06/Machine-Learning/tree/master/Data#basic-statistical-descriptions)
- [Machine Learning Process](https://github.com/vanikk06/Machine-Learning/tree/master/Data#machine-learning-process)

# Attributes
  > å±¬æ€§
  >> or dimensionsï¼ˆç¶­åº¦ï¼‰ã€featuresï¼ˆç‰¹å¾µï¼‰ã€variablesï¼ˆè®Šæ•¸ï¼‰
  
 A data field, representing a characteristic or featurbe of a data object.
  > E.g. IDã€nameã€address
  
  
#### Â§ ç¨®é¡ Â§

![](https://github.com/vanikk06/Machine-Learning/blob/master/Data/image/Snipaste_2020-02-06_23-13-16.png)

- Non-numericï¼šéæ•¸å€¼å‹
  - Nominalï¼šé¡åˆ¥å°ºåº¦ï¼Œç¨®é¡ï¼ˆcategoriesï¼‰ã€ç‹€æ…‹ï¼ˆstatesï¼‰æˆ–äº‹ç‰©åç¨±ï¼ˆnames of thingsï¼‰
    > E.g. redã€blue
      - Binaryï¼šäºŒé€²åˆ¶ï¼Œç‰¹å¾µåƒ…æœ‰ã€Œå…©å€‹ç‹€æ…‹ã€ï¼Œ0å’Œ1
        > ç‰¹æ®Šçš„Nominalæ¡ˆä¾‹
  - Ordinalï¼šé †åºå°ºåº¦ï¼Œå€¼èˆ‡å€¼ä¹‹é–“ç‚ºæœ‰æ„ç¾©çš„é †åºï¼ˆæœ‰å„ªåŠ£ã€å…ˆå¾Œå€åˆ†ï¼‰ï¼Œä½†é€£çºŒå€¼ä¹‹é–“çš„å¤§å°é—œä¿‚æœªçŸ¥
    > E.g. freshmanã€sophomoreã€juniorã€senior
  
- Numericï¼šæ•¸å€¼å‹
  >  Quantityï¼Œä»¥å¯å¦é€²è¡Œæ•¸å­¸é‹ç®—ä½œå€åˆ†
  >> ä¸»è¦ç”¨æ–¼**è¿´æ­¸åˆ†æ**
  
  - Interval-scaledï¼šå€é–“å°ºåº¦ï¼ˆç­‰è·ï¼‰
    > æ„ç¾©å¯åŠ æ¸›ã€ä¸å¯ä¹˜é™¤
    >> E.g. 100 â„ƒ\
    >> æº«åº¦0 â„ƒæ™‚ä»ç„¶æœ‰æº«åº¦ï¼Œæ‰€ä»¥ä¹˜é™¤æ˜¯æ²’æ„ç¾©çš„
      1. ä»¥**ç›¸åŒå¤§å°çš„å–®ä½**é€²è¡Œåº¦é‡
      2. å€¼æœ‰æ’åº
  - Ratio-scaledï¼šæ¯”ç‡å°ºåº¦ï¼ˆç­‰æ¯”ï¼‰
    > å¯é™¤æ³•ï¼Œå€æ•¸æœ‰æ„ç¾©
    >> E.g. 100 m
      1. å…·å›ºæœ‰çš„é›¶é»
      2. å€¼ä¹‹é–“å¯æ˜ç¢ºçš„é€²è¡Œæ•¸é‡ç´šçš„æ¯”è¼ƒ
         > E.g. 10mæ˜¯5mçš„å…©å€

[ğŸ¦¢](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

# Symmetric vs. Skewed Data
  > æ­£æ…‹åˆ†ä½ˆ èˆ‡ åæ…‹åˆ†ä½ˆ
 

![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/04/30195702/Stats1.png)

- normal distributionï¼šæ­£æ…‹åˆ†ä½ˆï¼Œè³‡æ–™å‘ˆã€Œå°ç¨±ã€åˆ†ä½ˆ
  > meanã€medianã€modeç›¸åŒ
- skewed distributionï¼šåæ…‹åˆ†ä½ˆ
  > å·¦å³ä»¥å°¾éƒ¨åˆ¤æ–·
  >> meanï¼šè½åœ¨ç´„ã€Œåº•éƒ¨é¢ç©ä¸€åŠã€çš„ä½ç½®
    - negatively skewed distributionï¼šè² åæ…‹ï¼Œåˆç¨± left skewed distributionï¼ˆå·¦åæ…‹ï¼‰ï¼Œè³‡æ–™å¤§å¤šé›†ä¸­æ–¼å³å´
      > Mode > Median > Mean
    - positively skewed distributionï¼šæ­£åæ…‹ï¼Œåˆç¨± right skewed distributionï¼ˆå³åæ…‹ï¼‰ï¼Œè³‡æ–™å¤§å¤šé›†ä¸­æ–¼å·¦å´
      > Mean > Median > Mode

#### Source
[Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/05/41-questions-on-statisitics-data-scientists-analysts/stats1/)

[æ­£æ…‹åˆ†ä½ˆï¼ˆnormal distributionï¼‰èˆ‡åæ…‹åˆ†ä½ˆï¼ˆskewed distributionï¼‰](https://www.itread01.com/content/1542005346.html)

[ğŸ•Š](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

# Basic Statistical Descriptions
  > åŸºæœ¬çµ±è¨ˆæè¿°
  
- Histogramï¼šç›´æ–¹åœ–ï¼Œxè»¸ç‚ºå€¼ï¼ˆvaluesï¼‰ï¼Œyè»¸ç‚ºæ¬¡æ•¸ã€é »ç‡ï¼ˆfrequenciesï¼‰
  > é€£çºŒå‹è³‡æ–™
  >> é•·æ¢é–“é»åœ¨ä¸€èµ·
- Boxplotï¼šç›’é¬šåœ–ï¼Œç”±äº”å€‹æ•¸çµ„æˆï¼Œåˆç¨±ã€Œäº”æ•¸ç¶œåˆåœ–ã€
  > [âœğŸ¼](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-boxplot-)
    - æœ€å¤§å€¼ï¼ˆMaxï¼‰
    - æœ€å°å€¼ï¼ˆminï¼‰
    - å››åˆ†ä½æ•¸ï¼šè³‡æ–™ç”±å°åˆ°å¤§æ’åº
        - Q1ï¼š25%
        - Q2ï¼š50%ï¼ˆä¸­ä½æ•¸ï¼‰
        - Q3ï¼š75%
- Scatter plotï¼šæ•£ä½ˆåœ–ï¼Œæ¯å°å€¼ç‚ºä¸€å°åº§æ¨™ï¼Œä¸¦åœ¨å¹³é¢ä¸­ç¹ªè£½ç‚ºé»
- å¸¸ç”¨è·é›¢å…¬å¼
    - æ­å¹¾é‡Œå¾—ï¼ˆEuclideanï¼‰è·é›¢ï¼šå¹³æ–¹ï¼†æ ¹è™Ÿ
    - æ›¼å“ˆé “ï¼ˆManhattanï¼‰è·é›¢ï¼šçµ•å°å€¼
    - åå¯å¤«æ–¯åŸºï¼ˆMinkowskiï¼‰è·é›¢ï¼šé€šå¼

#### Â§ Boxplot Â§

- IQRï¼ˆå››åˆ†ä½è·ï¼‰ï¼šQ3 - Q1
- é›¢ç¾¤å€¼ï¼šç¯„åœç‚ºã€Œå°æ–¼Q1 - 1.5IQRã€çš„å€¼èˆ‡ã€Œå¤§æ–¼Q3 + 1.5IQRã€çš„å€¼

```python
sum( )/4    #Q1

sum( )/2    #Q2

sum( )/4*3  #Q3
```

[ğŸ¦…](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)


# Machine Learning Process
  > æ©Ÿå™¨å­¸ç¿’æ­¥é©Ÿ
  
- **Step 1. æº–å‚™è³‡æ–™ï¼ˆåŒ…å«è³‡æ–™æ„ˆè™•ç†ï¼‰**
  
  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E6%BA%96%E5%82%99%E8%B3%87%E6%96%99-)

- **Step 2. é¸æ“‡æ¼”ç®—æ³•**

  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E9%81%B8%E6%93%87%E6%BC%94%E7%AE%97%E6%B3%95-)

- **Step 3. èª¿æ•´åƒæ•¸**

  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E8%AA%BF%E6%95%B4%E5%8F%83%E6%95%B8--%E8%A9%95%E4%BC%B0%E7%B5%90%E6%9E%9C-)

- **Step 4. è©•ä¼°çµæœ**

  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E8%AA%BF%E6%95%B4%E5%8F%83%E6%95%B8--%E8%A9%95%E4%BC%B0%E7%B5%90%E6%9E%9C-)

### Â§ æº–å‚™è³‡æ–™ Â§
> ä½¿ç”¨ Iris Data Setï¼ˆé³¶å°¾èŠ±å‰æ•¸æ“šé›†ï¼‰
>> ç‚º150å€‹æ¨£æœ¬ï¼Œå±¬æ–¼é³¶å°¾èŠ±ä¸‹çš„ä¸‰å€‹äºå±¬
>> - å±±é³¶å°¾ï¼ˆsetosaï¼‰
>> - è®Šè‰²é³¶å°¾ï¼ˆversicolorï¼‰
>> - ç¶­å‰å°¼äºé³¶å°¾ï¼ˆvirginicaï¼‰
>>> å„è‡ªçš„å››å€‹ç‰¹å¾µï¼šèŠ±è¼ï¼ˆSepalï¼‰å’ŒèŠ±ç“£ï¼ˆPetalï¼‰çš„é•·åº¦èˆ‡å¯¬åº¦

- Loading the Data
  ```python
  import pandas as pd

  df = pd.read_csv('iris.csv', header=None, names=names)
  ```
  - `pd.read_csv('æª”æ¡ˆå', header, names)`
      - headerï¼šæª”æ¡ˆæ˜¯å¦æœ‰æ¬„ä½å
        > header=Noneï¼šæ²’æœ‰æ¬„ä½å
      - namesï¼šæŒ‡å®šæ¬„ä½åç¨±
- Observing the data
  ```python
  df.head()
  
  df.info()
  
  df.describe()
  ```
  - `df.head()`ï¼šå‰äº”å‰äº”ç­†è³‡æ–™
  - `df.info()`ï¼šè³‡æ–™çš„åŸºæœ¬è³‡æ–™ï¼ˆå€‹æ•¸ã€è³‡æ–™é¡å‹...ï¼‰
  - `df.describe()`ï¼šåŸºæœ¬çš„çµ±è¨ˆè¨ˆç®—ï¼ˆå€‹æ•¸ã€å¹³å‡æ•¸ã€æ¨™æº–å·®...ï¼‰
  
- Plotting graph 
  > è—‰ç”±åœ–å½¢ä¾†è¼”åŠ©æˆ‘å€‘åˆ¤æ–·classåŠå…¶ä»–ç‰¹å¾µé—œä¿‚
  
  - matplotlib.pyplotï¼špythonç¹ªåœ–å¥—ä»¶
  - seabornï¼šmatplotlibçš„è£œå¼·ï¼Œä»¥matplotlibå»ºæ§‹çš„é«˜éšç¹ªåœ–å¥—ä»¶
  
  ```python
  import matplotlib.pyplot as plt
  import seaborn as sns
  
  plt.style.use('ggplot')
  sns.lmplot("sepal_length", "sepal_width", data=df, fit_reg=False, hue='class')
  ```
  - `plt.style.use()`ï¼šæŒ‡å®šå¥—ç”¨é¢¨æ ¼ã€ä¸»é¡Œ
    >  å¯çµåˆå…©ç¨®ä¸åŒçš„å…§å»ºé¢¨æ ¼ä½¿ç”¨ï¼Œä¹Ÿå¯è‡ªè¨‚é¢¨æ ¼
    >> [Learning more](https://medium.com/%E8%B3%87%E6%96%99%E8%A6%96%E8%A6%BA%E5%8C%96/matplotlib-06-%E5%9C%96%E8%A1%A8%E9%A2%A8%E6%A0%BC-d58498069700#2a92)
    
    ```python
    plt.style.use([â€œbmhâ€, â€œdark_backgroundâ€])
    ```
    - `plt.style.available`ï¼šå¯å°å‡ºæ‰€æœ‰å¯ç”¨çš„å…§å»ºé¢¨æ ¼
      
      ```python
      print(plt.style.available)
      ```
  - `sns.lmplot()`ï¼šè¿´æ­¸åœ–ï¼Œå¯ç›´è§€åœ°ç¸½è¦½æ•¸æ“šçš„å…§åœ¨é—œä¿‚
    > å¿…è¦åƒæ•¸ï¼šxã€yã€data
      - xã€yï¼šxè»¸ã€yè»¸è¦æ”¾ç½®çš„æ¬„ä½
        > å¿…é ˆæŒ‡å®šç‚º**å­—ç¬¦ä¸²**
        >> æ­¤ç¨®æ•¸æ“šæ ¼å¼ç¨±ç‚ºã€Œé•·æ ¼å¼ã€æˆ–ã€Œæ•´æ½”ã€æ•¸æ“š
      - dataï¼šæ•´å€‹è³‡æ–™è®Šæ•¸
      - fit_regï¼šæ˜¯å¦è¦æœ‰è¿´é—œç·š
        > é è¨­ç‚ºTrue
      - hueï¼šåˆ†é¡ï¼Œå®šç¾©æ•¸æ“šå­é›†
  
 ### Â§ é¸æ“‡æ¼”ç®—æ³• Â§
 
 - Split into train and test
   > å€åˆ†training dataã€testing dataï¼Œç”¨æ–¼äº¤å‰é©—è­‰
   
   å…ˆåŒ¯å…¥å¥—ä»¶
   ```python
   import numpy as np
   from sklearn.model_selection import train_test_split
   ```
   å†å°‡æ•¸æ“šå¾dataframeçš„è³‡æ–™æ ¼å¼è½‰æ›ç‚ºarrayï¼Œä¸¦æ”¾å…¥å‡½å¼ä¸­å°‡data setç”¨éš¨æ©Ÿåˆ†é…æ–¹å¼ï¼Œåˆ†å‰²ç‚º"training set"èˆ‡"testing set"
   ```python
   x = df.iloc[:,:-1].values
   y = df.iloc[:,4].values
   
   x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)
   ```
   > xç‚ºç‰¹å¾µè®Šæ•¸ï¼ˆclassä»¥å¤–çš„ï¼‰\
   > yç‚ºç›®æ¨™è®Šæ•¸ï¼ˆclassï¼‰
   
   - `df.iloc[row, column]`ï¼šé¸å–æ¬„ä½
      > åƒæ•¸ï¼šindex
   - `df.values`ï¼šå°‡dataframeè½‰ç‚ºarray
   -  `train_test_split(x, y, test_size, random_state)`ï¼šå°‡xã€yæŒ‰ç…§ç›¸åŒçš„éš¨æ©Ÿåˆ†é…é€²è¡Œåˆ‡å‰²
        - xï¼šç‰¹å¾µè®Šæ•¸
        - yï¼šç›®æ¨™è®Šæ•¸
        - test_sizeï¼šæ¸¬è©¦é›†å¤§å°
        - random_stateï¼šéš¨æ©ŸæŠ½å–çš„æ–¹å¼
          > PRG(Pseudo-random- Generator):å½éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨
   
- Algorithmï¼šK-NN
 
  ä½¿ç”¨K-NNï¼ˆk-nearest neighborï¼‰æ¼”ç®—æ³•ï¼Œç°¡å–®ä¾†èªªï¼Œå®ƒå‡è¨­æ¬²é æ¸¬é»æ˜¯iï¼Œæ‰¾å‡ºé›¢iæœ€è¿‘çš„kç­†è³‡æ–™å¤šæ•¸æ˜¯å“ªä¸€é¡ï¼Œä»¥æ­¤é æ¸¬içš„é¡å‹
  > Given a test instance i, find the k closest neighbors and their labels
Predict iâ€™s label as the majority of the labels of the k nearest neighbors.

  K-NNç‚ºç›£ç£å¼å­¸ç¿’çš„ä¸€ç¨®ï¼Œé©ç”¨æ–¼ã€Œæ•¸å€¼å‹ã€å’Œã€Œæ¨™ç¨±å‹ã€
    > æ¨™ç¨±å‹ï¼šç›®æ¨™è®Šæ•¸çš„çµæœï¼Œåªæœ‰åœ¨æœ‰é™ç›®æ¨™é›†ä¸­å–å€¼
    >> ä¸»è¦ç”¨æ–¼**åˆ†é¡**
    
  Step 1. ç¢ºå®š k å¤§å°
  
  Step 2. å°æ–¼ testing setä¸­çš„ä¸€å€‹æ¨£æœ¬ï¼Œæ‰¾åˆ° training set ä¸­å’Œå®ƒæœ€è¿‘çš„ k å€‹æ¨£æœ¬
  
  Step 3. å°‡é€™ k å€‹æ¨£æœ¬çš„æŠ•ç¥¨çµæœä½œç‚ºæ¸¬è©¦æ¨£æœ¬çš„é¡åˆ¥ï¼ˆå¤šæ•¸æ±ºï¼‰
  
  - å„ªé»ï¼š
      - ç²¾ç¢ºåº¦é«˜
      - å°é›¢ç¾¤å€¼ä¸æ•æ„Ÿ
      - ç„¡è³‡æ–™è¼¸å…¥å‡å®š
  - ç¼ºé»ï¼š
      - æ™‚é–“èˆ‡ç©ºé–“è¤‡é›œåº¦é«˜
      - è¨“ç·´æ¨¡å‹ä¾è³´è¨“ç·´é›†ï¼Œä¸”ä¸å¯ä¸Ÿæ£„
  
  ![](https://github.com/vanikk06/Machine-Learning/blob/master/Data/image/Snipaste_2020-02-08_03-14-14.png)
  
  åŒ¯å…¥å¥—ä»¶ï¼Œkç‚ºç”¨æˆ¶å®šç¾©çš„åƒæ•¸ï¼Œç‚ºæ–°è³‡æ–™é™„è¿‘çš„kå€‹é„°å±…
   > k çš„è¨­å®šå¾ˆé‡è¦ï¼Œå¥½çš„ k èƒ½å¤ è®“ training å‡ºä¾†çš„ model æœ‰è¶³å¤ çš„å½ˆæ€§ï¼Œé¿å…æ‰ Overfitting å’Œ Underfitting
   >> - è‹¥ k ç‚ºå¶æ•¸ï¼Œæœ‰å¯èƒ½ç¢°åˆ°ã€Œç„¡æ³•ç›´æ¥æ±ºå®šé¡åˆ¥ã€çš„æ™‚å€™ï¼Œéœ€å†é‡å°è©²ç‹€æ³ä½œexception handling
   >> - Overfittingï¼šç•¶ k=1 æ™‚ï¼Œæœƒå°è‡´éåº¦ç¬¦åˆtraining setçš„è³‡æ–™ç‰¹æ€§ï¼Œä½¿å…¶ç„¡æ³•é æ¸¬è¼ƒç‚ºæ™®éçš„è³‡æ–™
   >> - Underfittingï¼šç•¶ k=n ï¼ˆéå¤§ï¼‰æ™‚ï¼Œé æ¸¬çµæœä¸€å®šæ˜¯è³‡æ–™æ•¸é‡æœ€å¤šçš„é‚£é¡ï¼Œå°è‡´modelå¤±å»é æ¸¬èƒ½åŠ›
  
  ```python
  from sklearn.neighbors import KNeighborsClassifier
  
  knn = KNeighborsClassifier(n_neighbors=3)
  ```
  > è¦å‘ŠçŸ¥ k çš„å¤§å°
  
  æ“¬åˆmodelä¸¦é€²è¡Œé æ¸¬
  ```python
  knn.fit(x_train, y_train)
  
  pred = knn.predict(x_test)
  ```
  
  - `knn.fit(X, y)`ï¼šè¨“ç·´modelï¼Œæ‹¿training setå»è¨“ç·´model
     > Xã€yç‚ºtraining data
  - `knn.predict(X)`ï¼šé æ¸¬ï¼Œå°‡testing setæ”¾å…¥ç”±training setè¨“ç·´å‡ºçš„modelä¸­ï¼Œçœ‹modelçš„æº–ç¢ºç¨‹åº¦
     > Xç‚ºtesting data 
  
  è¨ˆç®—æ¨¡å‹æº–ç¢ºåº¦
  ```python
  from sklearn.metrics import accuracy_score
  
  accuracy_score(y_test, pred)
  ```
  
  - `accuracy_score(y_true, y_pred, normalize=True)`ï¼šè¨ˆç®—**åˆ†é¡å™¨**çš„æº–ç¢ºç‡
    > [Learning more](https://blog.csdn.net/CherDW/article/details/55813071)
      - y_trueï¼štesting setä¸­ y çš„çœŸå¯¦è³‡æ–™
      - y_predï¼šmodelé æ¸¬å‡ºçš„ y
      - normalizeï¼šæ˜¯å¦è¿”å›æ­£ç¢ºçš„åˆ†é¡æ¯”ä¾‹
          - Trueï¼šæ­£ç¢ºçš„åˆ†é¡æ¯”ä¾‹
          - Falseï¼šæ­£ç¢ºçš„åˆ†é¡æ¨£æœ¬æ•¸
 
 ### Â§ èª¿æ•´åƒæ•¸ ï¼† è©•ä¼°çµæœ Â§
 
 - cross-validationï¼šäº¤å‰é©—è­‰
    > é¿å…modelä¾è³´æŸä¸€ç‰¹å®šçš„training setèˆ‡testing setç”¢ç”Ÿåå·®
 
    ä¸€èˆ¬æˆ‘å€‘æœƒå°‡æ•¸æ“šåˆ†ç‚ºtraining setèˆ‡testing setï¼Œäº¤å‰é©—è­‰æ˜¯ä¸€ç¨®çµ±è¨ˆå­¸ä¸Šå°‡æ¨£æœ¬åˆ‡å‰²ç‚ºå¤šå€‹å°å­é›†ï¼Œä»¥ä¸åŒåˆ†å€ä½œç‚ºtrainingèˆ‡testingï¼Œä¸¦è¨ˆç®—ä¸åŒåˆ†å€ä¸Šçš„å¹³å‡å¾—åˆ†
    
    æ­¤æ¬¡ä½¿ç”¨K-Foldäº¤å‰é©—è­‰çš„æ–¹å¼ï¼Œä½¿ç”¨ä¸åŒçš„è³‡æ–™çµ„åˆä¾†é©—è­‰è¨“ç·´çš„model
    > E.g. å°‡è³‡æ–™åˆ†ç‚º10ç­‰ä»½ï¼Œå…¶ä¸­ã€Œç¬¬ä¸€ç­‰ä»½ã€ä½œç‚ºtesting setï¼Œå…¶é¤˜ä¹ç­‰ä»½ä½œç‚ºtraining setï¼›\
    ä¸‹ä¸€è¼ªï¼Œç¹¼çºŒå°‡ã€Œç¬¬äºŒç­‰ä»½ã€ä½œç‚ºtesting setï¼Œå‰©ä¸‹çš„ä¹ç­‰ä»½ä½œç‚ºtraining setï¼Œé‡è¤‡æ­¤å‹•ä½œåš10æ¬¡\
    æœ€å¾Œï¼Œè—‰ç”±å°‡10æ¬¡çš„æº–ç¢ºæ€§ï¼ˆAccuracyï¼‰å¹³å‡ï¼Œå¾—åˆ°çš„å¹³å‡å€¼å¯ä»¥åšç‚ºæˆ‘å€‘åˆ¤æ–·æº–ç¢ºåº¦æ˜¯å¦åå·®çš„æŒ‡æ¨™
    
    ![](https://i.imgur.com/tLWEE80.png)

    ```python
    from sklearn.model_selection import cross_val_score
    
    scores = cross_val_score(knn, x_train, y_train, cv=10, scoring='accuracy')
    print(scores)
    print(scores.mean())
    #è¼¸å‡º
    [0.91666667 0.72727273 0.90909091 0.81818182 0.9        0.88888889
    1.         1.         0.77777778 0.77777778]
    0.8715656565656567
    ```
    - `cross_val_score(estimator, X, y=None, cv=None, scoring=None)`ï¼šå°æ•¸æ“šé›†é€²è¡ŒæŒ‡å®šæ¬¡æ•¸çš„äº¤å‰é©—è­‰ï¼Œä¸¦ç‚ºæ¯æ¬¡é©—è­‰æ•ˆæœè©•æ¸¬
       > [Learning more](https://www.itread01.com/content/1541250025.html)
       - estimatorï¼šåˆ†é¡å™¨ï¼Œä¼°è¨ˆæ–¹æ³•å°è±¡
       - Xï¼šç‰¹å¾µè®Šæ•¸ï¼ˆfeaturesï¼‰
       - yï¼šç›®æ¨™è®Šæ•¸ï¼ˆLabelsï¼‰
       - cvï¼šåˆ†å¹¾çµ„
       - scoringï¼šåˆ†æ•¸è¨ˆç®—æ–¹æ³•
         - accuracyï¼šé¡¯ç¤ºæº–ç¢ºåº¦é«˜ä¸é«˜
           > æ„ˆé«˜æ„ˆå¥½
    
#### Source
[10åˆ†é’Ÿpythonå›¾è¡¨ç»˜åˆ¶ | seabornå…¥é—¨ï¼ˆå››ï¼‰ï¼šå›å½’æ¨¡å‹lmplot](https://zhuanlan.zhihu.com/p/25909753)
 
[Seaborn(sns)å®˜æ–¹æ–‡æ¡£å­¦ä¹ ç¬”è®°ï¼ˆç¬¬å››ç«  çº¿æ€§å…³ç³»çš„å¯è§†åŒ–ï¼‰](https://zhuanlan.zhihu.com/p/27593869)
 
[[Matplotlib-06]åœ–è¡¨é¢¨æ ¼](https://medium.com/%E8%B3%87%E6%96%99%E8%A6%96%E8%A6%BA%E5%8C%96/matplotlib-06-%E5%9C%96%E8%A1%A8%E9%A2%A8%E6%A0%BC-d58498069700)
 
[train_test_splitç”¨æ³•](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/37690/)
 
[kè¿‘é‚»--ä¸€ä¸ªæ‡’æƒ°å­¦ä¹ ç®—æ³•](https://ljalphabeta.gitbooks.io/python-/content/knn.html)
  
[kNNåˆ†é¡æ¼”ç®—æ³•](https://medium.com/@NorthBei/machine-learning-knn%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-b3e9b5aea8df)
 
[æ©Ÿå™¨å­¸ç¿’ï¼šKNNåˆ†é¡æ¼”ç®—æ³•ï¼](https://ithelp.ithome.com.tw/articles/10197110)
  
[sklearn.metricsä¸­çš„è¯„ä¼°æ–¹æ³•ä»‹ç»ï¼ˆaccuracy_score, recall_score, roc_curve, roc_auc_score, confusion_matrixï¼‰](https://blog.csdn.net/CherDW/article/details/55813071)
 
[sklearn ä¸­çš„äº¤å‰é©—è­‰](https://www.itread01.com/content/1541250025.html)

[sklearnä¸­çš„cross_val_score()å‡½æ•°å‚æ•°](https://blog.csdn.net/Asher117/article/details/87617702)

[äº¤å‰é©—è­‰(Cross-validation, CV)-K-fold CV](https://medium.com/@chih.sheng.huang821/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89-cross-validation-cv-3b2c714b18db#681e)

[æ©Ÿå™¨å­¸ç¿’ï¼šäº¤å‰é©—è­‰ï¼](https://ithelp.ithome.com.tw/articles/10197461)
  
[ğŸ¦ƒ](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)
