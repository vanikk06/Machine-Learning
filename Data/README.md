# Content
- [Attributes](https://github.com/vanikk06/Machine-Learning/tree/master/Data#attributes)
- [Symmetric vs. Skewed Data](https://github.com/vanikk06/Machine-Learning/tree/master/Data#symmetric-vs-skewed-data)
- [Basic Statistical Descriptions](https://github.com/vanikk06/Machine-Learning/tree/master/Data#basic-statistical-descriptions)
- [Machine Learning Process](https://github.com/vanikk06/Machine-Learning/tree/master/Data#machine-learning-process)
- [Data Pre-processing](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-pre-processing)
    - [Data description](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-description)
    - [Data cleaning](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-cleaning)
    - [Data integration](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-integration)
    - [Data transformation](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-transformation)
    - [Data reduction](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-reduction)
- [fit and transform](https://github.com/vanikk06/Machine-Learning/tree/master/Data#fit-and-transform)
- [Pandas map()ã€apply() and applymap()](https://github.com/vanikk06/Machine-Learning/tree/master/Data#pandas-mapapply-and-applymap)

# Attributes
  > å±¬æ€§
  >> or dimensionsï¼ˆç¶­åº¦ï¼‰ã€featuresï¼ˆç‰¹å¾µï¼‰ã€variablesï¼ˆè®Šæ•¸ï¼‰
  
 A data field, representing a characteristic or featurbe of a data object.
  > E.g. IDã€nameã€address
  
  
#### Â§ ç¨®é¡ Â§

![](https://github.com/vanikk06/Machine-Learning/blob/master/Data/image/Snipaste_2020-02-06_23-13-16.png)

- Non-numericï¼šéæ•¸å€¼å‹
  - Nominalï¼šé¡åˆ¥å°ºåº¦ï¼Œç¨®é¡ï¼ˆcategoriesï¼‰ã€ç‹€æ…‹ï¼ˆstatesï¼‰æˆ–äº‹ç‰©åç¨±ï¼ˆnames of thingsï¼‰
    > E.g. redã€blue
      - Binaryï¼šäºŒé€²åˆ¶ï¼Œç‰¹å¾µåƒ…æœ‰ã€Œå…©å€‹ç‹€æ…‹ã€ï¼Œ0å’Œ1
        > ç‰¹æ®Šçš„Nominalæ¡ˆä¾‹
  - Ordinalï¼šé †åºå°ºåº¦ï¼Œå€¼èˆ‡å€¼ä¹‹é–“ç‚ºæœ‰æ„ç¾©çš„é †åºï¼ˆæœ‰å„ªåŠ£ã€å…ˆå¾Œå€åˆ†ï¼‰ï¼Œä½†é€£çºŒå€¼ä¹‹é–“çš„å¤§å°é—œä¿‚æœªçŸ¥
    > E.g. freshmanã€sophomoreã€juniorã€senior
  
- Numericï¼šæ•¸å€¼å‹
  >  Quantityï¼Œä»¥å¯å¦é€²è¡Œæ•¸å­¸é‹ç®—ä½œå€åˆ†
  >> ä¸»è¦ç”¨æ–¼**è¿´æ­¸åˆ†æ**
  
  - Interval-scaledï¼šå€é–“å°ºåº¦ï¼ˆç­‰è·ï¼‰
    > æ„ç¾©å¯åŠ æ¸›ã€ä¸å¯ä¹˜é™¤
    >> E.g. 100 â„ƒ\
    >> æº«åº¦0 â„ƒæ™‚ä»ç„¶æœ‰æº«åº¦ï¼Œæ‰€ä»¥ä¹˜é™¤æ˜¯æ²’æ„ç¾©çš„
      1. ä»¥**ç›¸åŒå¤§å°çš„å–®ä½**é€²è¡Œåº¦é‡
      2. å€¼æœ‰æ’åº
  - Ratio-scaledï¼šæ¯”ç‡å°ºåº¦ï¼ˆç­‰æ¯”ï¼‰
    > å¯é™¤æ³•ï¼Œå€æ•¸æœ‰æ„ç¾©
    >> E.g. 100 m
      1. å…·å›ºæœ‰çš„é›¶é»
      2. å€¼ä¹‹é–“å¯æ˜ç¢ºçš„é€²è¡Œæ•¸é‡ç´šçš„æ¯”è¼ƒ
         > E.g. 10mæ˜¯5mçš„å…©å€

[ğŸ¦¢](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

# Symmetric vs. Skewed Data
  > æ­£æ…‹åˆ†ä½ˆ èˆ‡ åæ…‹åˆ†ä½ˆ
 

![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/04/30195702/Stats1.png)

- normal distributionï¼šæ­£æ…‹åˆ†ä½ˆï¼Œè³‡æ–™å‘ˆã€Œå°ç¨±ã€åˆ†ä½ˆ
  > meanã€medianã€modeç›¸åŒ
- skewed distributionï¼šåæ…‹åˆ†ä½ˆ
  > å·¦å³ä»¥å°¾éƒ¨åˆ¤æ–·
  >> meanï¼šè½åœ¨ç´„ã€Œåº•éƒ¨é¢ç©ä¸€åŠã€çš„ä½ç½®
    - negatively skewed distributionï¼šè² åæ…‹ï¼Œåˆç¨± left skewed distributionï¼ˆå·¦åæ…‹ï¼‰ï¼Œè³‡æ–™å¤§å¤šé›†ä¸­æ–¼å³å´
      > Mode > Median > Mean
    - positively skewed distributionï¼šæ­£åæ…‹ï¼Œåˆç¨± right skewed distributionï¼ˆå³åæ…‹ï¼‰ï¼Œè³‡æ–™å¤§å¤šé›†ä¸­æ–¼å·¦å´
      > Mean > Median > Mode

#### Source
[Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/05/41-questions-on-statisitics-data-scientists-analysts/stats1/)

[æ­£æ…‹åˆ†ä½ˆï¼ˆnormal distributionï¼‰èˆ‡åæ…‹åˆ†ä½ˆï¼ˆskewed distributionï¼‰](https://www.itread01.com/content/1542005346.html)

[ğŸ•Š](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

# Basic Statistical Descriptions
  > åŸºæœ¬çµ±è¨ˆæè¿°
  
- Histogramï¼šç›´æ–¹åœ–ï¼Œxè»¸ç‚ºå€¼ï¼ˆvaluesï¼‰ï¼Œyè»¸ç‚ºæ¬¡æ•¸ã€é »ç‡ï¼ˆfrequenciesï¼‰
  > é€£çºŒå‹è³‡æ–™
  >> é•·æ¢é–“é»åœ¨ä¸€èµ·
- Boxplotï¼šç›’é¬šåœ–ï¼Œç”±äº”å€‹æ•¸çµ„æˆï¼Œåˆç¨±ã€Œäº”æ•¸ç¶œåˆåœ–ã€
  > [âœğŸ¼](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-boxplot-)
    - æœ€å¤§å€¼ï¼ˆMaxï¼‰
    - æœ€å°å€¼ï¼ˆminï¼‰
    - å››åˆ†ä½æ•¸ï¼šè³‡æ–™ç”±å°åˆ°å¤§æ’åº
        - Q1ï¼š25%
        - Q2ï¼š50%ï¼ˆä¸­ä½æ•¸ï¼‰
        - Q3ï¼š75%
- Scatter plotï¼šæ•£ä½ˆåœ–ï¼Œæ¯å°å€¼ç‚ºä¸€å°åº§æ¨™ï¼Œä¸¦åœ¨å¹³é¢ä¸­ç¹ªè£½ç‚ºé»
- å¸¸ç”¨è·é›¢å…¬å¼
    - æ­å¹¾é‡Œå¾—ï¼ˆEuclideanï¼‰è·é›¢ï¼šå¹³æ–¹ï¼†æ ¹è™Ÿ
    - æ›¼å“ˆé “ï¼ˆManhattanï¼‰è·é›¢ï¼šçµ•å°å€¼
    - åå¯å¤«æ–¯åŸºï¼ˆMinkowskiï¼‰è·é›¢ï¼šé€šå¼

#### Â§ Boxplot Â§

- IQRï¼ˆå››åˆ†ä½è·ï¼‰ï¼šQ3 - Q1
- é›¢ç¾¤å€¼ï¼šç¯„åœç‚ºã€Œå°æ–¼Q1 - 1.5IQRã€çš„å€¼èˆ‡ã€Œå¤§æ–¼Q3 + 1.5IQRã€çš„å€¼

```python
sum( )/4    #Q1

sum( )/2    #Q2

sum( )/4*3  #Q3
```

[ğŸ¦…](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)


# Machine Learning Process
  > æ©Ÿå™¨å­¸ç¿’æ­¥é©Ÿ
  
- **Step 1. æº–å‚™è³‡æ–™ï¼ˆåŒ…å«è³‡æ–™æ„ˆè™•ç†ï¼‰**
  
  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E6%BA%96%E5%82%99%E8%B3%87%E6%96%99-)

- **Step 2. é¸æ“‡æ¼”ç®—æ³•**

  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E9%81%B8%E6%93%87%E6%BC%94%E7%AE%97%E6%B3%95-)

- **Step 3. èª¿æ•´åƒæ•¸**

  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E8%AA%BF%E6%95%B4%E5%8F%83%E6%95%B8--%E8%A9%95%E4%BC%B0%E7%B5%90%E6%9E%9C-)

- **Step 4. è©•ä¼°çµæœ**

  [Exercise](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-%E8%AA%BF%E6%95%B4%E5%8F%83%E6%95%B8--%E8%A9%95%E4%BC%B0%E7%B5%90%E6%9E%9C-)

### Â§ æº–å‚™è³‡æ–™ Â§
> ä½¿ç”¨ Iris Data Setï¼ˆé³¶å°¾èŠ±å‰æ•¸æ“šé›†ï¼‰
>> ç‚º150å€‹æ¨£æœ¬ï¼Œå±¬æ–¼é³¶å°¾èŠ±ä¸‹çš„ä¸‰å€‹äºå±¬
>> - å±±é³¶å°¾ï¼ˆsetosaï¼‰
>> - è®Šè‰²é³¶å°¾ï¼ˆversicolorï¼‰
>> - ç¶­å‰å°¼äºé³¶å°¾ï¼ˆvirginicaï¼‰
>>> å„è‡ªçš„å››å€‹ç‰¹å¾µï¼šèŠ±è¼ï¼ˆSepalï¼‰å’ŒèŠ±ç“£ï¼ˆPetalï¼‰çš„é•·åº¦èˆ‡å¯¬åº¦

- Loading the Data
  ```python
  import pandas as pd

  df = pd.read_csv('iris.csv', header=None, names=names)
  ```
  - `pd.read_csv('æª”æ¡ˆå', header, names)`
      - headerï¼šæª”æ¡ˆæ˜¯å¦æœ‰æ¬„ä½å
        > header=Noneï¼šæ²’æœ‰æ¬„ä½å
      - namesï¼šæŒ‡å®šæ¬„ä½åç¨±
- Observing the data
  ```python
  df.head()
  
  df.info()
  
  df.describe()
  ```
  - `df.head()`ï¼šå‰äº”å‰äº”ç­†è³‡æ–™
  - `df.info()`ï¼šè³‡æ–™çš„åŸºæœ¬è³‡æ–™ï¼ˆå€‹æ•¸ã€è³‡æ–™é¡å‹...ï¼‰
  - `df.describe()`ï¼šåŸºæœ¬çš„çµ±è¨ˆè¨ˆç®—ï¼ˆå€‹æ•¸ã€å¹³å‡æ•¸ã€æ¨™æº–å·®...ï¼‰
  
- Plotting graph 
  > è—‰ç”±åœ–å½¢ä¾†è¼”åŠ©æˆ‘å€‘åˆ¤æ–·classåŠå…¶ä»–ç‰¹å¾µé—œä¿‚
  
  - matplotlib.pyplotï¼špythonç¹ªåœ–å¥—ä»¶
  - seabornï¼šmatplotlibçš„è£œå¼·ï¼Œä»¥matplotlibå»ºæ§‹çš„é«˜éšç¹ªåœ–å¥—ä»¶
  
  ```python
  import matplotlib.pyplot as plt
  import seaborn as sns
  
  plt.style.use('ggplot')
  sns.lmplot("sepal_length", "sepal_width", data=df, fit_reg=False, hue='class')
  ```
  - `plt.style.use()`ï¼šæŒ‡å®šå¥—ç”¨é¢¨æ ¼ã€ä¸»é¡Œ
    >  å¯çµåˆå…©ç¨®ä¸åŒçš„å…§å»ºé¢¨æ ¼ä½¿ç”¨ï¼Œä¹Ÿå¯è‡ªè¨‚é¢¨æ ¼
    >> [Learning more](https://medium.com/%E8%B3%87%E6%96%99%E8%A6%96%E8%A6%BA%E5%8C%96/matplotlib-06-%E5%9C%96%E8%A1%A8%E9%A2%A8%E6%A0%BC-d58498069700#2a92)
    
    ```python
    plt.style.use([â€œbmhâ€, â€œdark_backgroundâ€])
    ```
    - `plt.style.available`ï¼šå¯å°å‡ºæ‰€æœ‰å¯ç”¨çš„å…§å»ºé¢¨æ ¼
      
      ```python
      print(plt.style.available)
      ```
  - `sns.lmplot()`ï¼šè¿´æ­¸åœ–ï¼Œå¯ç›´è§€åœ°ç¸½è¦½æ•¸æ“šçš„å…§åœ¨é—œä¿‚
    > å¿…è¦åƒæ•¸ï¼šxã€yã€data
      - xã€yï¼šxè»¸ã€yè»¸è¦æ”¾ç½®çš„æ¬„ä½
        > å¿…é ˆæŒ‡å®šç‚º**å­—ç¬¦ä¸²**
        >> æ­¤ç¨®æ•¸æ“šæ ¼å¼ç¨±ç‚ºã€Œé•·æ ¼å¼ã€æˆ–ã€Œæ•´æ½”ã€æ•¸æ“š
      - dataï¼šæ•´å€‹è³‡æ–™è®Šæ•¸
      - fit_regï¼šæ˜¯å¦è¦æœ‰è¿´é—œç·š
        > é è¨­ç‚ºTrue
      - hueï¼šåˆ†é¡ï¼Œå®šç¾©æ•¸æ“šå­é›†
  
 ### Â§ é¸æ“‡æ¼”ç®—æ³• Â§
 
 - Split into train and test
   > é©—è­‰model
   >> å€åˆ†training dataã€testing dataï¼Œç”¨æ–¼äº¤å‰é©—è­‰
   
   é€²è¡Œmodelé©—è­‰çš„ä¸€å€‹é‡è¦ç›®çš„ï¼Œæ˜¯è¦é¸å‡ºä¸€å€‹é©åˆçš„modelï¼Œå°ç›£ç£å¼å­¸ç¿’è€Œè¨€ï¼Œæˆ‘å€‘å¸Œæœ›model**å°æ–¼æœªçŸ¥æ•¸æ“šçš„æ³›åŒ–èƒ½åŠ›å¼·**
   
   å…ˆåŒ¯å…¥å¥—ä»¶
   ```python
   import numpy as np
   from sklearn.model_selection import train_test_split
   ```
   å†å°‡æ•¸æ“šå¾dataframeçš„è³‡æ–™æ ¼å¼è½‰æ›ç‚ºarrayï¼Œä¸¦æ”¾å…¥å‡½å¼ä¸­å°‡data setç”¨éš¨æ©Ÿåˆ†é…æ–¹å¼ï¼Œåˆ†å‰²ç‚º"training set"èˆ‡"testing set"
   ```python
   x = df.iloc[:,:-1].values
   y = df.iloc[:,4].values
   
   x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)
   ```
   > xç‚ºç‰¹å¾µè®Šæ•¸ï¼ˆclassä»¥å¤–çš„ï¼‰\
   > yç‚ºç›®æ¨™è®Šæ•¸ï¼ˆclassï¼‰
   
   - `df.iloc[row, column]`ï¼šé¸å–æ¬„ä½
      > åƒæ•¸ï¼šindex
   - `df.values`ï¼šå°‡dataframeè½‰ç‚ºarray
   -  `train_test_split(x, y, test_size, random_state)`ï¼šå°‡xã€yæŒ‰ç…§ç›¸åŒçš„éš¨æ©Ÿåˆ†é…é€²è¡Œåˆ‡å‰²
        - xï¼šç‰¹å¾µè®Šæ•¸
        - yï¼šç›®æ¨™è®Šæ•¸
        - test_sizeï¼šæ¸¬è©¦é›†å¤§å°
        - random_stateï¼šéš¨æ©ŸæŠ½å–çš„æ–¹å¼
          > PRG(Pseudo-random- Generator):å½éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨
   
- Algorithmï¼šK-NN
  > K-NNï¼šç‰©ä»¥é¡èš
 
  ä½¿ç”¨K-NNï¼ˆk-nearest neighborï¼‰æ¼”ç®—æ³•ï¼Œç°¡å–®ä¾†èªªï¼Œå®ƒå‡è¨­æ¬²é æ¸¬é»æ˜¯iï¼Œæ‰¾å‡ºé›¢iæœ€è¿‘çš„kç­†è³‡æ–™å¤šæ•¸æ˜¯å“ªä¸€é¡ï¼Œä»¥æ­¤é æ¸¬içš„é¡å‹
  > Given a test instance i, find the k closest neighbors and their labels
Predict iâ€™s label as the majority of the labels of the k nearest neighbors.

  K-NNç‚ºç›£ç£å¼å­¸ç¿’çš„ä¸€ç¨®ï¼Œé©ç”¨æ–¼ã€Œæ•¸å€¼å‹ã€å’Œã€Œæ¨™ç¨±å‹ã€
    > æ¨™ç¨±å‹ï¼šç›®æ¨™è®Šæ•¸çš„çµæœï¼Œåªæœ‰åœ¨æœ‰é™ç›®æ¨™é›†ä¸­å–å€¼
    >> ä¸»è¦ç”¨æ–¼**åˆ†é¡**
    
  Step 1. ç¢ºå®š k å¤§å°
  
  Step 2. å°æ–¼ testing setä¸­çš„ä¸€å€‹æ¨£æœ¬ï¼Œæ‰¾åˆ° training set ä¸­å’Œå®ƒæœ€è¿‘çš„ k å€‹æ¨£æœ¬
  
  Step 3. å°‡é€™ k å€‹æ¨£æœ¬çš„æŠ•ç¥¨çµæœä½œç‚ºæ¸¬è©¦æ¨£æœ¬çš„é¡åˆ¥ï¼ˆå¤šæ•¸æ±ºï¼‰
  
  - å„ªé»ï¼š
      - ç²¾ç¢ºåº¦é«˜
      - å°é›¢ç¾¤å€¼ä¸æ•æ„Ÿ
      - ç„¡è³‡æ–™è¼¸å…¥å‡å®š
  - ç¼ºé»ï¼š
      - æ™‚é–“èˆ‡ç©ºé–“è¤‡é›œåº¦é«˜
      - è¨“ç·´æ¨¡å‹ä¾è³´è¨“ç·´é›†ï¼Œä¸”ä¸å¯ä¸Ÿæ£„
  
  ![](https://github.com/vanikk06/Machine-Learning/blob/master/Data/image/Snipaste_2020-02-08_03-14-14.png)
  
  åŒ¯å…¥å¥—ä»¶ï¼Œkç‚ºç”¨æˆ¶å®šç¾©çš„åƒæ•¸ï¼Œç‚ºæ–°è³‡æ–™é™„è¿‘çš„kå€‹é„°å±…
   > k çš„è¨­å®šå¾ˆé‡è¦ï¼Œå¥½çš„ k èƒ½å¤ è®“ training å‡ºä¾†çš„ model æœ‰è¶³å¤ çš„å½ˆæ€§ï¼Œé¿å…æ‰ Overfitting å’Œ Underfitting
   >> - è‹¥ k ç‚ºå¶æ•¸ï¼Œæœ‰å¯èƒ½ç¢°åˆ°ã€Œç„¡æ³•ç›´æ¥æ±ºå®šé¡åˆ¥ã€çš„æ™‚å€™ï¼Œéœ€å†é‡å°è©²ç‹€æ³ä½œexception handling
   >> - Overfittingï¼šç•¶ k=1 æ™‚ï¼Œæœƒå°è‡´éåº¦ç¬¦åˆtraining setçš„è³‡æ–™ç‰¹æ€§ï¼Œä½¿å…¶ç„¡æ³•é æ¸¬è¼ƒç‚ºæ™®éçš„è³‡æ–™
   >> - Underfittingï¼šç•¶ k=n ï¼ˆéå¤§ï¼‰æ™‚ï¼Œé æ¸¬çµæœä¸€å®šæ˜¯è³‡æ–™æ•¸é‡æœ€å¤šçš„é‚£é¡ï¼Œå°è‡´modelå¤±å»é æ¸¬èƒ½åŠ›
  
  ```python
  from sklearn.neighbors import KNeighborsClassifier
  
  knn = KNeighborsClassifier(n_neighbors=3)
  ```
  > è¦å‘ŠçŸ¥ k çš„å¤§å°
  
  æ“¬åˆmodelä¸¦é€²è¡Œé æ¸¬
  ```python
  knn.fit(x_train, y_train)
  
  pred = knn.predict(x_test)
  ```
  
  - `knn.fit(X, y)`ï¼šè¨“ç·´modelï¼Œæ‹¿training setå»è¨“ç·´model
     > Xã€yç‚ºtraining data
  - `knn.predict(X)`ï¼šé æ¸¬ï¼Œå°‡testing setæ”¾å…¥ç”±training setè¨“ç·´å‡ºçš„modelä¸­ï¼Œçœ‹modelçš„æº–ç¢ºç¨‹åº¦ï¼ˆé æ¸¬è¡¨ç¾èƒ½åŠ›ï¼‰
     > Xç‚ºtesting data 
  
  è¨ˆç®—æ¨¡å‹æº–ç¢ºåº¦
  ```python
  from sklearn.metrics import accuracy_score
  
  accuracy_score(y_test, pred)
  ```
  
  - `accuracy_score(y_true, y_pred, normalize=True)`ï¼šè¨ˆç®—**åˆ†é¡å™¨**çš„æº–ç¢ºç‡
    > [Learning more](https://blog.csdn.net/CherDW/article/details/55813071)
      - y_trueï¼štesting setä¸­ y çš„çœŸå¯¦è³‡æ–™
      - y_predï¼šmodelé æ¸¬å‡ºçš„ y
      - normalizeï¼šæ˜¯å¦è¿”å›æ­£ç¢ºçš„åˆ†é¡æ¯”ä¾‹
          - Trueï¼šæ­£ç¢ºçš„åˆ†é¡æ¯”ä¾‹
          - Falseï¼šæ­£ç¢ºçš„åˆ†é¡æ¨£æœ¬æ•¸
 
 ### Â§ èª¿æ•´åƒæ•¸ ï¼† è©•ä¼°çµæœ Â§

 - cross-validationï¼šäº¤å‰é©—è­‰
    > æª¢é©—modelæ–¹æ³•ï¼Œå”åŠ©èª¿ç¯€åƒæ•¸
    >> é¿å…modelä¾è³´æŸä¸€ç‰¹å®šçš„training setèˆ‡testing setç”¢ç”Ÿ**åå·®**
 
    ä¸€èˆ¬æˆ‘å€‘æœƒå°‡æ•¸æ“šåˆ†ç‚ºtraining setèˆ‡testing setï¼Œäº¤å‰é©—è­‰æ˜¯ä¸€ç¨®çµ±è¨ˆå­¸ä¸Šå°‡æ¨£æœ¬åˆ‡å‰²ç‚ºå¤šå€‹å°å­é›†ï¼Œä»¥ä¸åŒåˆ†å€ä½œç‚ºtrainingèˆ‡testingï¼Œä¸¦è¨ˆç®—ä¸åŒåˆ†å€ä¸Šçš„å¹³å‡å¾—åˆ†
    
    æ­¤æ¬¡ä½¿ç”¨K-Foldäº¤å‰é©—è­‰çš„æ–¹å¼ï¼Œä½¿ç”¨ä¸åŒçš„è³‡æ–™çµ„åˆä¾†é©—è­‰è¨“ç·´çš„model
    > E.g. å°‡è³‡æ–™åˆ†ç‚º10ç­‰ä»½ï¼Œå…¶ä¸­ã€Œç¬¬ä¸€ç­‰ä»½ã€ä½œç‚ºtesting setï¼Œå…¶é¤˜ä¹ç­‰ä»½ä½œç‚ºtraining setï¼›\
    ä¸‹ä¸€è¼ªï¼Œç¹¼çºŒå°‡ã€Œç¬¬äºŒç­‰ä»½ã€ä½œç‚ºtesting setï¼Œå‰©ä¸‹çš„ä¹ç­‰ä»½ä½œç‚ºtraining setï¼Œé‡è¤‡æ­¤å‹•ä½œåš10æ¬¡\
    æœ€å¾Œï¼Œè—‰ç”±å°‡10æ¬¡çš„æº–ç¢ºæ€§ï¼ˆAccuracyï¼‰å¹³å‡ï¼Œå¾—åˆ°çš„å¹³å‡å€¼å¯ä»¥åšç‚ºæˆ‘å€‘åˆ¤æ–·æº–ç¢ºåº¦æ˜¯å¦åå·®çš„æŒ‡æ¨™
    
    ![](https://i.imgur.com/tLWEE80.png)

    ```python
    from sklearn.model_selection import cross_val_score
    
    scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')
    print(scores)
    print(scores.mean())
    #è¼¸å‡º
    [0.91666667 0.72727273 0.90909091 0.81818182 0.9        0.88888889
    1.         1.         0.77777778 0.77777778]
    0.8715656565656567
    ```
    - `cross_val_score(estimator, X, y=None, cv=None, scoring=None)`ï¼šå°æ•¸æ“šé›†é€²è¡ŒæŒ‡å®šæ¬¡æ•¸çš„äº¤å‰é©—è­‰ï¼Œä¸¦ç‚ºæ¯æ¬¡é©—è­‰æ•ˆæœè©•æ¸¬
       > [Learning more](https://www.itread01.com/content/1541250025.html)
       - estimatorï¼šåˆ†é¡å™¨ï¼Œä¼°è¨ˆæ–¹æ³•å°è±¡
       - Xï¼šç‰¹å¾µè®Šæ•¸ï¼ˆfeaturesï¼‰ï¼Œéœ€æ”¾å…¥å®Œæ•´è³‡æ–™
       - yï¼šç›®æ¨™è®Šæ•¸ï¼ˆLabelsï¼‰ï¼Œéœ€æ”¾å…¥å®Œæ•´è³‡æ–™
       - cvï¼šåˆ†å¹¾çµ„
       - scoringï¼šåˆ†æ•¸è¨ˆç®—æ–¹æ³•
         - accuracyï¼šé¡¯ç¤ºæº–ç¢ºåº¦é«˜ä¸é«˜
           > æ„ˆé«˜æ„ˆå¥½


    äº¤å‰æª¢é©—ç‚ºé©—è­‰modelçš„æ–¹æ³•ï¼Œè€Œæ­¤æ¬¡modelæ˜¯ä¾ç…§K-NNæ¼”ç®—æ³•å»è¨“ç·´å‡ºçš„ï¼Œç”¨æˆ¶è‡ªè¡Œè¨­å®šçš„ k ä¹Ÿæœƒå½±éŸ¿åˆ° model çš„å¥½å£ï¼Œå¸¶å…¥ä¸åŒçš„ k é€²è¡Œäº¤å‰æª¢é©—ï¼Œçœ‹å“ªå€‹æ¨¡å‹çš„åˆ†æ•¸è¼ƒé«˜ï¼Œä»¥æ­¤æ‰¾å‡ºæœ€é©ç•¶çš„ k
    
    ```python
    neighbors = [x for x in range(1,50) if x%2 != 0]
    cv_scores = []
    
    for k in neighbors:
      knn = KNeighborsClassifier(n_neighbors=k)
      scores = cross_val_score(knn, x, y, cv=10, scoring='accuracy')
      cv_scores.append(scores.mean())
    ```
    > cv_scoresç‚ºä¸åŒmodelï¼ˆç”±ä¸åŒ k è¨“ç·´ï¼‰å„è‡ªçš„æº–ç¢ºåº¦å¹³å‡

    - changing to misclassification errorï¼šåˆ†é¡éŒ¯èª¤
      > MSEï¼šå‡æ–¹èª¤å·®ï¼Œé æ¸¬å€¼èˆ‡çœŸå¯¦å€¼ä¹‹é–“å·®ç•°çš„å‡æ–¹å€¼(å¤§å°)
      
      ```python
      MSE = [1-x for x in cv_scores]
      ```
      
    - determining best kï¼šæ‰¾å‡ºæœ€ä½³çš„ k
      
      ```python
      optimal_k = neighbors[MSE.index(min(MSE))]
      
      print("The optimal number of neighbors is %d" % optimal_k)
      #è¼¸å‡º
      The optimal number of neighbors is 7
      ```
        - `index(x, start, end)`ï¼šlistä¸­ç¬¬ä¸€å€‹åŒ¹é…çš„å€¼
            - xï¼šæŸ¥æ‰¾çš„å°è±¡
            - start, endï¼šé–‹å§‹çµæŸçš„ç¯„åœ
        - æ ¼å¼åŒ–æ“ä½œ
        
          ```python
          print("I'm %s. I'm %d years old." % ("kid", 18))
          print("Hi, %s. I'm %s" % ('mom', 'kid'))
          #è¼¸å‡º
          I'm kid. I'm 18 years old.
          Hi, mom. I'm kid
          ```
           - %sï¼šå­—ç¬¦ä¸²
           - %dï¼šåé€²ä½åˆ¶æ•´æ•¸
           
     - plot misclassification error vs. kï¼šç•«å‡ºã€Œåˆ†é¡èª¤å·®ã€èˆ‡ã€Œkã€ä¹‹é–“çš„æŠ˜ç·šåœ–
     
       ```python
       plt.plot(neighbors, MSE)
       plt.xlabel('Number of neighbors k')
       plt.ylabel('Misclassification Error')
       ```
       > ç”±åœ–å¯çœ‹å‡ºï¼Œç•¶ k æ•¸å­—å¤§åˆ°ä¸€å®šç¨‹åº¦æ™‚ï¼Œmodelåˆ†é¡çš„éŒ¯èª¤ç‡ä¹Ÿæœƒæ„ˆä¾†æ„ˆé«˜

#### Source   
[10åˆ†é’Ÿpythonå›¾è¡¨ç»˜åˆ¶ | seabornå…¥é—¨ï¼ˆå››ï¼‰ï¼šå›å½’æ¨¡å‹lmplot](https://zhuanlan.zhihu.com/p/25909753)
 
[Seaborn(sns)å®˜æ–¹æ–‡æ¡£å­¦ä¹ ç¬”è®°ï¼ˆç¬¬å››ç«  çº¿æ€§å…³ç³»çš„å¯è§†åŒ–ï¼‰](https://zhuanlan.zhihu.com/p/27593869)
 
[[Matplotlib-06]åœ–è¡¨é¢¨æ ¼](https://medium.com/%E8%B3%87%E6%96%99%E8%A6%96%E8%A6%BA%E5%8C%96/matplotlib-06-%E5%9C%96%E8%A1%A8%E9%A2%A8%E6%A0%BC-d58498069700)
 
[train_test_splitç”¨æ³•](https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/37690/)
 
[kè¿‘é‚»--ä¸€ä¸ªæ‡’æƒ°å­¦ä¹ ç®—æ³•](https://ljalphabeta.gitbooks.io/python-/content/knn.html)
  
[kNNåˆ†é¡æ¼”ç®—æ³•](https://medium.com/@NorthBei/machine-learning-knn%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-b3e9b5aea8df)
 
[æ©Ÿå™¨å­¸ç¿’ï¼šKNNåˆ†é¡æ¼”ç®—æ³•ï¼](https://ithelp.ithome.com.tw/articles/10197110)
  
[sklearn.metricsä¸­çš„è¯„ä¼°æ–¹æ³•ä»‹ç»ï¼ˆaccuracy_score, recall_score, roc_curve, roc_auc_score, confusion_matrixï¼‰](https://blog.csdn.net/CherDW/article/details/55813071)
 
[sklearn ä¸­çš„äº¤å‰é©—è­‰](https://www.itread01.com/content/1541250025.html)

[sklearnä¸­çš„cross_val_score()å‡½æ•°å‚æ•°](https://blog.csdn.net/Asher117/article/details/87617702)

[äº¤å‰é©—è­‰(Cross-validation, CV)-K-fold CV](https://medium.com/@chih.sheng.huang821/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89-cross-validation-cv-3b2c714b18db#681e)

[æ©Ÿå™¨å­¸ç¿’ï¼šäº¤å‰é©—è­‰ï¼](https://ithelp.ithome.com.tw/articles/10197461)

[cross_val_scoreäº¤å‰éªŒè¯åŠå…¶ç”¨äºå‚æ•°é€‰æ‹©ã€æ¨¡å‹é€‰æ‹©ã€ç‰¹å¾é€‰æ‹©](https://blog.csdn.net/weixin_38536057/article/details/78702564)
 
[æ©Ÿå™¨/æ·±åº¦å­¸ç¿’: åŸºç¤ä»‹ç´¹-æå¤±å‡½æ•¸(loss function)](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E4%BB%8B%E7%B4%B9-%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-loss-function-2dcac5ebb6cb) 
 
[ğŸ¦ƒ](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

# Data Pre-processing
  > è³‡æ–™é è™•ç†

åœ¨çœŸå¯¦ä¸–ç•Œä¸­çš„è³‡æ–™æ˜¯**ä¸ä¹¾æ·¨çš„ï¼ˆDirtyï¼‰**ï¼Œå†é€²è¡Œåˆ†æä¹‹å‰ï¼Œå¿…é ˆå…ˆå°è³‡æ–™åšäº›è™•ç†ï¼Œå¦å‰‡æœƒåˆ†æå‡ºçš„çµæœ
> garbage in, garbage outï¼ˆGIGOï¼‰
>> æ²’æœ‰é«˜å“è³ªçš„è³‡æ–™ï¼Œå°±æ²’æœ‰é«˜å“è³ªçš„æ¢å‹˜çµæœ

- ä¸ä¹¾æ·¨çš„è³‡æ–™å¯èƒ½å‡ºç¾çš„å•é¡Œ
    1. ä¸å®Œæ•´ï¼ˆIncompleteï¼‰ï¼šç¼ºå°‘ã€Œå±¬æ€§å€¼ã€æˆ–ã€ŒæŸäº›æœ‰åƒ¹å€¼çš„å±¬æ€§ã€ï¼Œä¹Ÿå¯èƒ½ã€Œåƒ…åŒ…å«èšé›†è³‡æ–™ã€
       > E.g. è·æ¥­=' ', å…¬å¸äººæ•¸=20ï¼ˆå…¬å¸äººæ•¸ç‚ºèšé›†è³‡æ–™ï¼Œè€Œç„¡å…¬å¸äººå“¡è³‡æ–™ï¼‰
    2. æœ‰é›œè¨Šï¼ˆNoiseï¼‰ï¼šåŒ…å«ã€ŒéŒ¯èª¤ã€æˆ–ã€Œé›¢ç•°å€¼/é›¢ç¾¤å€¼ã€
    3. ä¸ä¸€è‡´ï¼ˆInconsistentï¼‰ï¼šè³‡æ–™æœ¬èº«æˆ–å‘½åä¸Šä¸ä¸€è‡´


- åœ¨è³‡æ–™é è™•ç†ä¸­ï¼Œä¸»è¦åŒ…å«å››é …å·¥ä½œ
    - è³‡æ–™æ¸…ç†(Data Cleaning)ï¼š
      > [âœğŸ»](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-cleaning)
        - å¡«å…¥**éºå¤±å€¼**
        - æ‰¾å‡ºä¸”ç§»é™¤**é›¢ç•°å€¼ï¼ˆé›œè¨Šï¼‰**
        - è§£æ±º**ä¸ä¸€è‡´**
    - è³‡æ–™æ•´åˆ(Data Integration)ï¼šæ•´åˆ**ä¸åŒä¾†æº**çš„è³‡æ–™åº«æˆ–æª”æ¡ˆ
      > [âœğŸ¼](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-integration)
    - è³‡æ–™è½‰æ›(Data Transformation)ï¼š**æ¨™æº–åŒ–**èˆ‡**èšåˆ**
      > [âœğŸ¾](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-transformation)
    - è³‡æ–™ç¸®æ¸›(Data Reduction)ï¼šé™ä½è³‡æ–™é‡çš„å¤§å°ï¼Œä¸¦é æœŸèƒ½ç²å¾—ç›¸åŒæˆ–è¿‘ä¼¼çš„åˆ†æçµæœ
      > [âœğŸ¿](https://github.com/vanikk06/Machine-Learning/tree/master/Data#data-reduction)

[ğŸ“](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

## Data description 
   > è³‡æ–™æè¿°
   
è‹¥è¦è³‡æ–™é è™•ç†æˆåŠŸï¼Œå°è³‡æ–™æœ‰**å…¨ç›¤çš„æ¦‚å¿µ**æ˜¯å¾ˆé‡è¦çš„

- Descriptive Data Summarizationï¼šæ•˜è¿°è³‡æ–™å½™ç¸½ï¼Œç”¨æ–¼èªªæ˜è³‡æ–™æ•´é«”ç‰¹æ€§ï¼Œä¸¦æŒ‡å‡ºå“ªäº›è³‡æ–™å€¼ç‚ºé›œè¨Šæˆ–é›¢ç•°å€¼

    ä¸»è¦æƒ³çŸ¥é“çš„è³‡æ–™æ•´é«”ç‰¹æ€§ï¼š
    > çµ±è¨ˆè³‡è¨Š
    
    - ä¸»è¦å‚¾å‘
        - Meanï¼šå¹³å‡æ•¸
        - Mediamï¼šä¸­ä½æ•¸
        - Modeï¼šçœ¾æ•¸            
    - è³‡æ–™æ•£ä½ˆ
        - Quartilesï¼šå››åˆ†ä½æ•¸
        - Varianceï¼šè®Šç•°æ•¸

[ğŸ“ğŸ“](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)


## Data cleaning
   > è³‡æ–™æ¸…ç†
   
- å¡«è£œ**éºå¤±å€¼**
  > [âœğŸ¼](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-missing-value-)
- æ‰¾å‡º**Outliers**ä¸¦æ·¡åŒ–ï¼ˆå¹³æ»‘ï¼‰é›œè¨Š
  > [âœğŸ»](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-noisy-data-)
- ä¿®æ­£è³‡æ–™çš„**ä¸ä¸€è‡´**
- è§£æ±ºè³‡æ–™æ•´åˆæ‰€é€ æˆçš„**é‡è¤‡**


#### Â§ Missing value Â§

é€šå¸¸åœ¨é€²è¡Œåˆ†é¡æ™‚ï¼Œå€¼çµ„çš„é¡åˆ¥è³‡æ–™æœ‰å¯èƒ½æ˜¯éºå¤±çš„ç‹€æ³ï¼Œç•¶å°åˆ†æçµæœæœ‰é‡å¤§å½±éŸ¿çš„è³‡æ–™å±¬æ€§å­˜åœ¨éºå¤±å€¼æ™‚ï¼Œåˆ†ææ•ˆæœæœƒå¾ˆå·®

- Method 1ï¼šå¿½ç•¥
    > ä¸æ˜¯å¾ˆæœ‰æ•ˆï¼Œé™¤éè¨±å¤šå€¼çµ„çš„å±¬æ€§åŒ…å«éºå¤±å€¼
- Method 2ï¼š**äººå·¥æ–¹å¼**å¡«å…¥éºå¤±å€¼
    > è²»æ™‚ä¸”ä¸å¯¦éš›
- Method 3ï¼šè‡ªå‹•å¡«å…¥
    - åˆ©ç”¨**å…¨åŸŸå¸¸æ•¸ï¼ˆGlobal Constantï¼‰**
      > E.g. "æœªçŸ¥", "Â±âˆ"
    - ä½¿ç”¨**å¹³å‡å€¼ã€ä¸­ä½æ•¸æˆ–çœ¾æ•¸**
        - æ•¸å€¼å‹ï¼šå¹³å‡æ•¸
          > ç¢ºä¿ç„¡æ¥µç«¯å€¼
        - é †åºå‹ï¼šä¸­ä½æ•¸
        - é¡åˆ¥å‹ï¼šçœ¾æ•¸
    - ä½¿ç”¨**ç›¸åŒé¡åˆ¥å€¼çµ„çš„å±¬æ€§å¹³å‡å€¼**
      > è³‡æ–™é¡å‹ç‚ºæ•¸å€¼å‹
    - ä½¿ç”¨**æœ€æœ‰å¯èƒ½çš„å€¼**ï¼šå¯é€éè¿´æ­¸ã€è²æ°ç†è«–ç­‰æ¨è«–å¼å·¥å…·ï¼Œæˆ–æ±ºç­–æ¨¹æ¨è«–ä¾†æ±ºå®š
    
   æ©Ÿå™¨å­¸ç¿’çš„modelæ˜¯åˆ©ç”¨**ç©ºé–“ä¸­çš„è·é›¢**ä¾†åšè¿´æ­¸æˆ–æ˜¯åˆ†é¡ï¼Œè‹¥è³‡æ–™ä¸­æœ‰ç¼ºå€¼ï¼Œå°±ç„¡æ³•åœ¨ç©ºé–“ä¸­è¡¨ç¾ä½ç½®ï¼Œéœ€è¦è™•ç†

    ```python
    import pandas as pd

    df = pd.read_csv('data.csv')
    ```

   æŸ¥çœ‹æ˜¯å¦æœ‰éºå¤±å€¼
    ```python
    df.isnull()

    df.isnull().sum() #ç¸½åˆ
    ```
     - `df.isnull()`ï¼šæ˜¯å¦ç‚ºç©ºå€¼/éºå¤±å€¼
        > å›å‚³å¸ƒæ—å€¼çš„dataframe
        
   åˆªé™¤éºå¤±å€¼
     ```python
     df.dropna(axis=0) #row
     
     df.dropna(axis=1) #column
     
     df.dropna(how='all') #æŒ‡å®š
     
     df.dropna(subset=['C'])  #åˆªæ‰Cå…§æœ‰missing valueçš„row
     ```
     - `df.dropna(axis, how, subset, inplace)`ï¼šç§»é™¤éºå¤±å€¼
        - axisï¼šæŒ‰ä½•æ–¹å‘
            - axis=0ï¼šé è¨­ï¼ŒæŒ‰**rowæ–¹å‘**åˆªé™¤
              > å«æœ‰éºå¤±å€¼çš„rowæœƒè¢«åˆªé™¤
              >> ä¸€èˆ¬è™•ç†éºå¤±å€¼ï¼Œä¸å¤ªæœƒå°‡æ•´ç­†è³‡æ–™åˆªé™¤
            - axis=1ï¼šæŒ‰**columnæ–¹å‘**åˆªé™¤
              > å«æœ‰éºå¤±å€¼çš„columnæœƒè¢«åˆªé™¤
        - howï¼šæŒ‡å®šåˆªé™¤æ¢ä»¶
            - anyï¼šé è¨­ï¼Œåªè¦å«æœ‰éºå¤±å€¼ï¼Œå³åˆªé™¤é‚£rowæˆ–column
            - allï¼šç•¶å…¨éƒ¨è³‡æ–™ç‚ºéºå¤±å€¼æ™‚ï¼Œå³åˆªé™¤é‚£rowæˆ–column
        - subsetï¼šæŒ‡å®šç‰¹å®šç‰¹å¾µ
        - inplaceï¼šæ˜¯å¦æ”¹è®ŠåŸå§‹è³‡æ–™
          > é è¨­ç‚ºFalse
          
   å¡«è£œéºå¤±å€¼
     ```python
     df.fillna(0) #è£œä¸Šå›ºå®šå€¼
     ```
     - `df.fillna()`ï¼šè£œä¸Šéºå¤±å€¼
   
   ä½¿ç”¨`sklearn.preprocessing`å¥—ä»¶å…§çš„ Imputer ä¾†è¨“ç·´ model ä»¥å¡«è£œéºå¤±å€¼
     ```python
     from sklearn.preprocessing import Imputer
      
     imr = Imputer(missing_values='NaN', strategy = 'mean', axis=0) 
     imr = imr.fit(df.values)
     imputed_data = imr.transform(df.values)
     imputed_data
     #è¼¸å‡º
     array([[ 1. ,  2. ,  3. ,  4. ],
            [ 5. ,  6. ,  7.5,  8. ],
            [ 0. , 11. , 12. ,  6. ]])
     ```
     - `Imputer(missing_values='NaN', strategy='mean', axis=0)`ï¼šä½¿ç”¨æ•¸æ“šçš„**çµ±è¨ˆè¨Šæ¯**ï¼ˆå¹³å‡å€¼ã€ä¸­ä½æ•¸...ç­‰ï¼‰ä¾†å¡«è£œéºå¤±å€¼
         - missing_valuesï¼šéºå¤±å€¼è¡¨ç¤ºç¬¦ï¼Œå¯ç‚ºæ•´æ•¸æˆ–NaN
            > é è¨­å€¼ç‚º'NaN'
            >> NaNï¼šç‚ºnumpy.nanç”¨å­—ç¬¦ä¸²
         - strategyï¼šæ›¿æ›ç­–ç•¥ï¼Œå­—ç¬¦ä¸²
              - 'mean'ï¼šé è¨­ï¼Œç”¨axisçš„å¹³å‡å€¼å¡«è£œ
              - 'median'ï¼šç”¨axisçš„ä¸­ä½æ•¸å¡«è£œ
              - 'most_frequent'ï¼šç”¨axisçš„çœ¾æ•¸å¡«è£œ
         - axisï¼šæŒ‡å®šè»¸å‘
              - axis=0ï¼šé è¨­ï¼Œè¨ˆç®—columnsï¼ˆæŒ‰æ¬„ä½ï¼‰
              - axis=1ï¼šè¨ˆç®—rowsï¼ˆæŒ‰å–®ç­†è³‡æ–™ï¼‰
     - `imr.fit(X)`ï¼šè¨ˆç®— training set çš„çµ±è¨ˆå€¼ï¼Œå„²å­˜çµ±è¨ˆå€¼
         - Xï¼šè¨“ç·´modelè®Šæ•¸ï¼Œè³‡æ–™å‹æ…‹ç‚ºarray              
     - `imr.transform(X)`ï¼šå°‡çµ±è¨ˆå€¼æ‡‰ç”¨æ–¼ testing set
         - Xï¼šè¨ˆç®—missing valuesæ–¼Xä¸­
         
   å¦ä¸€å€‹ä¾‹å­ï¼Œä¹Ÿå¯ä½¿ç”¨**åŠ æ¬Šå¹³å‡å¼**çš„æ–¹å¼ï¼Œå¦‚ä¹‹å‰æåˆ°çš„K-NNæ¼”ç®—æ³•ï¼Œç‰©ä»¥é¡èšï¼Œé€éè¨ˆç®—ä¸åŒç¶­åº¦ä¹‹é–“çš„é—œä¿‚ä¾†æ‰¾å‡ºæœ€æœ‰å¯èƒ½çš„ç­”æ¡ˆï¼Œä¹Ÿå°±æ˜¯ä»¥ä¸åŒç¶­åº¦ä¹‹é–“çš„é—œä¿‚ï¼ˆè·é›¢ï¼‰ä½œç‚ºæ¬Šé‡çš„å¤§å°ï¼Œè·é›¢æ„ˆè¿‘çš„è¦æ„ˆç›¸ä¼¼
   
   - æ¬Šé‡ï¼šè·é›¢çš„å€’æ•¸ï¼Œå¦å…¶åŠ ç¸½ç‚º1æ‰å¯ä½¿ç”¨
     > ä¸€ç¨®æ¼”ç®—åŸºç¤æ¨™æº–åŒ–çš„æ–¹å¼
     >> E.g. å‡è¨­ç¸½å…±æœ‰4ç­†è³‡æ–™ï¼ˆG1-G4ï¼‰ï¼Œæ¯ç­†è³‡æ–™å„æœ‰5å€‹å±¬æ€§ï¼ˆE1-E5ï¼‰\
             G3åœ¨E1çš„ä½ç½®ç‚ºéºå¤±å€¼\
             å¯ä»¥åˆ©ç”¨è¨ˆç®—G3å…¶E2-E5å±¬æ€§èˆ‡å…¶ä»–ç­†è³‡æ–™çš„E2-E5å±¬æ€§ä¹‹é–“çš„è·é›¢ï¼Œè½‰æ›ç‚ºæ¬Šé‡ï¼Œé€éå…¶ä»–3ç­†è³‡æ–™çš„E1å€¼æ­é…æ¬Šé‡è¨ˆç®—ï¼Œä»¥æ­¤æ¨æ¸¬G3çš„E1ç‚ºä½•
   
   æŸ¥è©¢èªªæ˜æ–‡ä»¶
     ```python
     help('imputer')
     ```
     
     - `help()`ï¼šæŸ¥è©¢èªªæ˜æ–‡ä»¶
        > è³‡æ–™å‹æ…‹ï¼šå­—ä¸²
    
#### Â§ Noisy data Â§
  > æœ‰å¯èƒ½ç‚ºã€Œé›¢ç¾¤å€¼ã€ã€ã€Œé›¢æ•£å€¼ã€ï¼Œå°è‡´è³‡æ–™å‘ˆç¾æ›²æŠ˜

è™•è£¡é€™é¡è³‡æ–™ï¼Œå¯åˆ†ç‚ºå››ç¨®æ–¹æ³•ï¼š
1. ç®±ç‹€æ³•ï¼ˆBinningï¼‰
2. è¿´æ­¸ï¼ˆRegressionï¼‰
3. èšé¡ï¼ˆClusteringï¼‰
4. æ•´åˆé›»è…¦èˆ‡äººæª¢é©—ï¼šåˆ©ç”¨äººæª¢é©—æœ‰å•é¡Œçš„å€¼
   > E.g.è™•è£¡å¯èƒ½é›¢ç•°å€¼
 
- ç®±ç‹€æ³•ï¼ˆBinningï¼‰ï¼šå…ˆå°‡è³‡æ–™é€²è¡Œæ’åºï¼Œå†åˆ©ç”¨å…¶é„°å±…çš„å€¼é€²è¡Œ**å¹³æ»‘åŒ–**
  > ç‚ºè€ƒé‡ç®±å…§è³‡æ–™ä¹‹ã€Œé„°å±…ã€ï¼ˆNeighborhoodï¼‰çš„å€¼ï¼Œå› æ­¤å±¬æ–¼**å€åŸŸå¹³æ»‘æ³•ï¼ˆLocal Smoothingï¼‰**æ–¹æ³•
    - Step 1. æ’åºï¼šå°‡è³‡æ–™åˆ†æˆæ•¸å€‹é »ç‡ç›¸åŒçš„çš„ç®±å­ï¼ˆBucketsã€Binsï¼‰
      > é »ç‡ç›¸åŒï¼šç®±å…§è³‡æ–™ç­†æ•¸ç›¸åŒ
      >> E.g. å°‡ä¹ç­†è³‡æ–™åˆ†ç‚º4,8,15,21,21,24,25,28,34
        - ç­‰å¯¬ï¼š**è·é›¢**åˆ†å‰²ï¼Œåˆ‡å‰²æˆnå€‹ç­‰å¯¬ç¯„åœçš„ç®±å­
          > E.g.\
            è³‡æ–™ï¼š\[4,8], [15], [21,21,24,25,28], [34]\
            ç®±å­ï¼š[-, 10), [10, 20), [20, 30), [30, +)
          
            - æ˜“å—é›¢ç•°å€¼ä¸»å°
            - å°åæ–œè³‡æ–™è™•ç†è¼ƒå·®
         
        - ç­‰æ·±ï¼š**é »ç‡**åˆ†å‰²ï¼Œåˆ‡å‰²æˆæœ‰ã€Œå¤§ç´„ç›¸åŒã€æ¨£æœ¬æ•¸çš„ç®±å­(è¼ƒå¸¸ä½¿ç”¨)
          > E.g.\
          è³‡æ–™ï¼š\[4,8,15], [21,21,24], [25,28,34]\
          ç®±å­ï¼š\[-, 20), \[20, 25) \[25, 35)
            - è³‡æ–™é‡åº¦æ€§
    
    - Step 2. å¹³æ»‘åŒ–ï¼šæ¯å€‹ç®±å­ç¨ç«‹ï¼Œå°å„å€‹ç®±å­å…§çš„è³‡æ–™é€²è¡Œå¹³æ»‘åŒ–
      > ç®±å­å¯¬åº¦æ„ˆå¤§ï¼Œæ„ˆå¹³æ»‘
        - å¹³å‡å€¼ã€ä¸­é–“å€¼ï¼šä»¥å¹³å‡å€¼/ä¸­é–“å€¼æ›¿ä»£ç®±å…§æ‰€æœ‰çš„å€¼ï¼Œä»¥é€²è¡Œå¹³æ»‘åŒ–
          > E.g. \[9,9,9], [22,22,22], [29,29,29]
        - é‚Šç•Œå€¼ï¼ˆBin Boundariesï¼‰ï¼šä»¥ç®±å­å…§è³‡æ–™çš„ Max èˆ‡ min ä½œåŸºæº–ï¼Œå°‡å…¶ä»–è³‡æ–™ä»¥æœ€æ¥è¿‘çš„é‚Šç•Œå€¼å–ä»£
          > E.g. \[4,4,15], [21,21,24], [25,25,34] 

- è¿´æ­¸ï¼ˆRegressionï¼‰ï¼šé€éå°‡è³‡æ–™åˆ†ä½ˆæƒ…æ³å°æ‡‰è‡³å‡½æ•¸ï¼Œä¾†é€²è¡Œå¹³æ»‘åŒ–
  > å°‡é›¢ç¾¤å€¼ç”¨ã€Œè¿´æ­¸ç·šä¸Šå°æ‡‰çš„é»ã€å–ä»£
  
- èšé¡ï¼ˆClusteringï¼‰ï¼šåµæ¸¬èšé¡ï¼Œä¸¦ç§»é™¤é›¢ç•°å€¼

#### Source
[sklearn.preprocessingä¸­çš„Imputerç”¨æ³•è§£æ](https://www.chzzz.club/post/212.html)

[sklearn.preprocessing.Imputer](https://blog.csdn.net/kancy110/article/details/75041923)

[Python æ©Ÿå™¨å­¸ç¿’ Scikit-learn å®Œå…¨å…¥é–€æŒ‡å—](https://kknews.cc/zh-tw/code/g5qoogm.html)


[ğŸ“ğŸ“ğŸ“](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)


## Data integration
   > è³‡æ–™æ•´åˆ
   
- å¤šæºï¼šå°‡è¨±å¤šä¾†æºçš„è³‡æ–™ï¼Œæ•´åˆæˆä¸€å€‹**å…·é€£è²«æ€§**çš„è³‡æ–™
  > E.g. é‡åŒ–å–®ä½ä¸åŒ
  
- å¤šé¤˜ï¼š
    - ä¸€å€‹å±¬æ€§å¯ç”±å…¶ä»–**å–®ä¸€å±¬æ€§**æˆ–**ä¸€çµ„å±¬æ€§**å°å‡º
    - å±¬æ€§ä¸ä¸€è‡´æˆ–å±¬æ€§å‘½åä¸ä¸€è‡´
    
- ç™¼æ˜ä¸¦è§£æ±ºè³‡æ–™å€¼è¡çªå•é¡Œï¼šçœŸå¯¦ä¸–ç•Œçš„å€‹é«”ï¼Œå±¬æ€§å€¼æœ‰å¯èƒ½ä¾†è‡ªä¸åŒä¾†æº
    > E.g. ä¸åŒè¡¨ç¤ºã€ä¸åŒé‡åŒ–
       
   
[ğŸ“ğŸ“ğŸ“ğŸ“](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)  


## Data transformation
   > è³‡æ–™è½‰æ›
   
- Normalizationï¼šæ­£å‰‡åŒ–ï¼Œè®“è³‡æ–™åœ¨åŸå§‹çš„æ¨£æ…‹ä¸‹ï¼Œ**ç­‰æ¯”ç¸®æ”¾**è½åœ¨\[0, 1]å€é–“ä¸­
  > å°‡è³‡æ–™åŸæœ¬çš„ min-Max è½‰æ›ç‚º new_min-new_Maxï¼Œä¸”ä¸æ”¹è®ŠåŸæœ¬åˆ†ä½ˆ
 
- Standardizationï¼šæ¨™æº–åŒ–ï¼Œå°‡åŸå§‹è³‡æ–™è½‰æ›æˆç¬¦åˆæ¨™æº–å¸¸æ…‹åˆ†ä½ˆçš„æ¨£æ…‹
  > å„ªé»ï¼š
  >  1. æå‡modelçš„æ”¶æ–‚é€Ÿåº¦
  >  2. æå‡modelçš„ç²¾æº–åº¦ï¼šå¯è®“æ¯å€‹ç‰¹å¾µå€¼å°çµæœåšå‡ºç›¸è¿‘ç¨‹åº¦çš„è²¢ç»
    
    - æ¨™æº–å¸¸æ…‹åˆ†é…ï¼ˆStandard Normal Distributionï¼‰ï¼šå¹³å‡å€¼ç‚º0ï¼Œæ¨™æº–åŒ–ç‚º1
        - ä¸€å€‹æ¨™æº–å·®ï¼š68%
        - å…©å€‹æ¨™æº–å·®ï¼š95%
        - ä¸‰å€‹æ¨™æº–å·®ï¼š99.7%
        
- Z-scoreï¼šä»£è¡¨åŸå§‹è³‡æ–™å’Œæ¯é«”å¹³å‡å€¼ä¹‹é–“çš„è·é›¢ï¼Œä»¥æ¨™æº–å·®ç‚ºå–®ä½è¨ˆç®—
  > ç¶“æ­¤è½‰æ›å¾Œï¼Œè³‡æ–™å°‡ç¬¦åˆæ¨™æº–å¸¸æ…‹åˆ†ä½ˆ

    ![](https://raw.githubusercontent.com/chenkenanalytic/img/master/tm-01/f01.png)
    
- åé€²ä½æ¨™æº–åŒ–ï¼šå¯è®“è³‡æ–™ä»‹æ–¼\[0, 1]ä¹‹é–“


#### Â§ Exercise Â§
    
   ç·´ç¿’è™•ç†ä¸åŒé¡å‹çš„è³‡æ–™ï¼Œå¿…é ˆå°‡éæ•¸å€¼å‹è³‡æ–™è½‰æ›æ•¸å€¼å‹ï¼Œæ‰å¯ä¸Ÿå…¥modelè¨“ç·´
   > å¤§éƒ¨åˆ†modelæ˜¯åŸºæ–¼æ•¸å­¸é‹ç®—

- éæ•¸å€¼å‹
    - **é †åºå‹**ç‰¹å¾µï¼šå®šç¾©**å°æ‡‰å­—å…¸ï¼ˆmapping dictionaryï¼‰**
      
      ```python
      df = pd.DataFrame([['green', 'M', 10.1, 'class1'],
                         ['red', 'L', 13.5, 'class2'],
                         ['blue', 'XL', 15.3, 'class1']])
                         
      df.columns = ['color', 'size', 'price', 'classlabel']
      ```
      - `pd.DataFrame()`ï¼šç”Ÿæˆä¸€å€‹dataframe
      - `.columns`ï¼šdataframeæ¬„ä½åç¨±
      
      åˆ©ç”¨å­—å…¸å°‡ã€Œé †åºå‹ã€è³‡æ–™ï¼Œè½‰æ›ç‚ºã€Œæ•¸å€¼å‹ã€
       ```python
       size_mapping = {'XL':3, 'L':2, 'M':1}
       
       df['size'] = df['size'].map(size_mapping)
       ```
       - `.map()`ï¼šç”¨æ–¼Seriesç‰©ä»¶æˆ–DataFrameå°è±¡çš„ä¸€æ¬„ï¼Œæ¥æ”¶å‡½æ•¸æˆ–å­—å…¸ä½œç‚ºåƒæ•¸ï¼Œè¿”å›ç¶“å‡½æ•¸æˆ–å­—å…¸è™•ç†å¾Œçš„å€¼
         > å°ç‰©ä»¶å…§æ¯å€‹å…ƒç´ åšè™•ç†
         
           è‹¥è¦åè½‰å­—å…¸æ˜ å°„å¾Œçš„çµæœï¼Œä¹Ÿå°±æ˜¯è¦è¿”å›value:keyçš„çµæœï¼Œå¯ä»¥åˆ©ç”¨å­—å…¸ä¸­çš„`.item()`
           ```python
           inv_size_mapping = {v:k for k, v in size_mapping.items()}
           df['size'] = df['size'].map(inv_size_mapping)
           ```
    - **é¡åˆ¥å‹**ç‰¹å¾µï¼šå°‡é¡åˆ¥æ¨™ç±¤è½‰æ›ç‚ºæ•´æ•¸å€¼
       
         - Method 1ï¼šå°æ‡‰å­—å…¸
           > é©ç”¨å°å–®æ¬„è³‡æ–™
           
           å…ˆæŒ‘å‡ºå”¯ä¸€å€¼ï¼Œå†æ”¾å…¥å­—å…¸ä¸­åšæ˜ å°„
           
           ```python
           import numpy as np
           
           class_mapping = {label:idx for idx, label in enumerate(np.unique(df['classlabel']))}
           class_mapping
           #è¼¸å‡º
           {'class1': 0, 'class2': 1}
           
           df['classlabel'] = df['classlabel'].map(class_mapping)
           ```
           
           - `np.unique(array, return_index=False)`ï¼šé™¤å»é‡è¤‡å€¼ï¼Œè¿”å›å”¯ä¸€å€¼
              > è¿”å› array ï¼Œè‹¥inputç‚ºé 1-D arrayæœƒå£“å¹³ç‚º 1-D\
              >  - ã€Œæ•¸å€¼å‹ã€èˆ‡ã€Œå­—ä¸²å‹ã€ä¸å¯åŒæ™‚æ”¾åœ¨ä¸€èµ·ï¼Œæœƒå‡ºç¾éŒ¯èª¤
              >  - è‹¥è¿”å›arrayå…§ç‚ºæ•¸å€¼å‹ï¼Œæœƒç”±å°åˆ°å¤§æ’åˆ—
              >> ä¸å½±éŸ¿åŸå§‹è³‡æ–™

                - arrayï¼šinput
                - return_indexï¼šé è¨­ç‚ºFalseï¼Œæ˜¯å¦å›å‚³å”¯ä¸€å€¼åœ¨åŸå§‹è³‡æ–™ä¸­çš„ä½ç½®
                  > å›å‚³å€¼ç‚º arrayï¼Œæœƒå¦å­˜åœ¨å”¯ä¸€å€¼ä»¥å¤–çš„arrayä¸­

               ```python
               a = [1,6,43,7,7,7,1,2,4,6]
               A = np.unique(a)
               A
               #è¼¸å‡º
               array([ 1,  2,  4,  6,  7, 43])
               ```
               è¿”å›å”¯ä¸€å€¼åŸå§‹çš„ä½ç½®
               ```python
               A, i = np.unique(a, return_index=True)

               A
               #è¼¸å‡º           
               array([ 1,  2,  4,  6,  7, 43])

               i
               #è¼¸å‡º
               array([0, 7, 8, 1, 3, 2], dtype=int64)
               ```
           
           - `enumerate()`ï¼šæšèˆ‰ï¼Œè¨ˆç®—å…ƒç´ ä½ç½®
              > æœƒå°‡listçš„indexèˆ‡listçš„å…ƒç´ ï¼ˆitemï¼‰ï¼ŒåŒ…æˆä¸€å€‹tupleï¼Œå†å°‡æ¯å€‹tupleåŒ…æˆæŒ‰indexæ’åºçš„list

              ```python
              list(enumerate(np.unique(df['classlabel'])))
              #è¼¸å‡º
              [(0, 'class1'), (1, 'class2')]        
              ```

              åœ¨å­—å…¸ä¸­ï¼Œæ˜¯è¦å°‡åŸæœ¬ã€Œé¡åˆ¥å‹ã€è³‡æ–™è½‰æ›ç‚ºã€Œæ•¸å€¼å‹ã€ï¼Œå› æ­¤è¦æ”¹è®Šidxèˆ‡labelä½ç½®

              ```python
              for idx, label in enumerate(np.unique(df['classlabel'])):
                     print('{}:{}'.format(label, idx))

              #è¼¸å‡º
              class1:0
              class2:1
              ```
         - Method 2ï¼šä½¿ç”¨LabelEncoder
           > æœƒå°‡æ¯å€‹é¡åˆ¥ mapping åˆ°æŸå€‹**æ•´æ•¸**ï¼Œä¸æœƒå¢åŠ æ–°æ¬„ä½
           >> é©ç”¨æ–¼ã€Œæœ‰åºã€é›¢æ•£å€¼ï¼Œå› æ•´æ•¸æœ‰å¤§å°ä¹‹åˆ†
           
           
           æ”¾å…¥ LabelEncoderçš„æ¨¡å‹ï¼Œå»è½‰æ›é¡åˆ¥å‹è³‡æ–™ï¼Œä¸é ˆç‰¹åˆ¥å»å®šç¾©è½‰æ›å°è±¡
           ```python
           from sklearn.preprocessing import LabelEncoder
           
           class_le = LabelEncoder()
           df['classlabel'] = class_le.fit_transform(df['classlabel'].values)    
           ```
           
            - `.fit_transform()`ï¼šè¨“ç·´modelä¸¦å–ä»£ä¹‹ 
              > inputï¼šarray
            - `.inverse_transform`ï¼šå°‡æ•¸å€¼å‹è½‰æ›ç‚ºåŸæœ¬çš„é¡åˆ¥å‹            
            
                ```python            
                df['classlabel'] = class_le.inverse_transform(df['classlabel'])
                ```
           æ›å€‹æ–¹å¼å°å¦ä¸€å€‹æ¬„ä½åšè™•ç†
           ```python
           X = df[['color', 'size', 'price']].values
           
           color_le = LabelEncoder()
           X[:,0] = color_le.fit_transform(X[:,0])
           X
           #è¼¸å‡º
           array([[1, 1, 10.1],
           [2, 2, 13.5],
           [0, 3, 15.3]], dtype=object)
           ```
           > blue=0, green=1, red=2
           >> 0,1,2æœ‰å¤§å°ä¹‹åˆ†ï¼Œä½†åç›®ç‰¹å¾µæœ¬èº«ç„¡
           
   
           
         
         
        
        





#### Source
[è³‡æ–™çš„æ­£è¦åŒ–(Normalization)åŠæ¨™æº–åŒ–(Standardization)](https://aifreeblog.herokuapp.com/posts/54/data_science_203/)

[æ¨™æº–åˆ†æ•¸](https://zh.wikipedia.org/wiki/%E6%A8%99%E6%BA%96%E5%88%86%E6%95%B8#%E6%A6%82%E5%BF%B5)

[è³‡æ–™é è™•ç†â€”â€”æ¨™æº–åŒ–ã€æ­¸ä¸€åŒ–ã€æ­£å‰‡åŒ–](https://www.itread01.com/content/1541512225.html)

[pandas map()ç”¨æ³•](https://blog.csdn.net/y12345678904/article/details/72385656)

[ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)  

## Data reduction
   > è³‡æ–™å£“ç¸®
   
   
   
[ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“ğŸ“](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)     


# fit and transform

- fit()ï¼šä¸€å€‹è¨“ç·´ model çš„éç¨‹ï¼Œå¯æ±‚å¾— training set çš„å›ºæœ‰å±¬æ€§ï¼ˆå¹³å‡å€¼ã€æ¨™æº–å·®ã€æœ€å¤§ã€æœ€å°...ç­‰ç­‰ï¼‰

- transform()ï¼šåœ¨fit()çš„åŸºç¤ä¸Šï¼Œé€²è¡Œæ¨™æº–åŒ–ã€é™ç¶­ã€æ­¸ä¸€åŒ–...ç­‰æ“ä½œ
  > å› å»ºç«‹åœ¨fit()åŸºç¤ä¹‹ä¸Šï¼Œè‹¥ç›´æ¥åŸ·è¡Œæœƒå‡ºéŒ¯
  
- fit_transform()ï¼šçµåˆfit()èˆ‡transform()


[ğŸ¦œ](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)

# Pandas map()ã€apply() and applymap()
  > çš†ä¸æ”¹è®ŠåŸå§‹è³‡æ–™

Pandasä¸­ã€Œæ˜ å°„ã€èˆ‡ã€Œæ‡‰ç”¨ã€å…©ä¸­æ–¹æ³•çš„æ•´ç†æ‡‰ç”¨

- Series
  > Seriesç‰©ä»¶ æˆ– dataframe ä¸­çš„ä»»ä¸€æ¬„
  >> [âœğŸ¾](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-series-)
    - `map()`ï¼šå¯å°Seriesç‰©ä»¶ä¸­çš„æ¯å€‹å…ƒç´ ï¼ŒåŸ·è¡Œçµ¦å®šçš„functionã€dictionaryã€Seriesæ˜ å°„è™•ç†ï¼ˆåªè¦å…ƒç´ å¯ä»¥ä¸€ä¸€å°æ‡‰å³å¯ï¼‰
    - `apply(function, agrs)`ï¼šèƒ½å°ç‰©ä»¶åŸ·è¡Œçµ¦å®šçš„functionï¼Œé‚„èƒ½è¨­å®šæŒ‡å®šåƒæ•¸ï¼ˆargsï¼‰
      > é©ç”¨æ–¼Seriesèˆ‡dataframe
          - functionï¼šè¦åŸ·è¡Œçš„å‡½å¼
          - agrsï¼štupleï¼ŒæŒ‡å®šfunctionå…§åƒæ•¸
            > å‰æï¼Œfunctioné ˆç‚ºå…©å€‹ä»¥ä¸Šåƒæ•¸
      
- DataFrame
  > ç„¡map()
  >> [âœğŸ½](https://github.com/vanikk06/Machine-Learning/tree/master/Data#-dataframe-)
    - `apply(function, agrs)`ï¼šé‡å°columnçš„aggregatesï¼ˆåˆé›†ï¼‰æ“ä½œ
       > è‹¥çµ¦å®šçš„å‡½æ•¸æ˜¯ufuncï¼Œä¹Ÿæœƒæœ‰element-wiseæ•ˆæœ
         - Aggregate functionsï¼šåˆè¨ˆå‡½æ•¸ï¼ŒSQLä¸­ä¸€ç¨®åŸºæœ¬çš„å‡½æ•¸é¡å‹ï¼ŒæŒ‡**æ“ä½œé¢å‘ç‚ºä¸€ç³»åˆ—çš„å€¼ï¼Œä¸¦è¿”å›ä¸€å€‹å–®ä¸€å€¼**
           > E.g. countã€maxã€minã€sumã€avg(å¹³å‡)...ç­‰ç­‰
           >> å›å‚³Series
         - universal functionï¼šç¸®å¯«ç‚ºufuncï¼Œé€™é¡å‡½æ•¸èƒ½å¤ ä½œç”¨æ–¼narrayå°è±¡ä¸­çš„**æ¯ä¸€å€‹å…ƒç´ ä¸Š**ï¼Œè€Œåˆ†é‡å°narrayå°è±¡æ“ä½œ
           > [Learning more](https://blog.csdn.net/unixtch/article/details/78531585)
              
    - `applymap()`ï¼šé‡å°element-wiseæ“ä½œ
       > element-wiseï¼šæŒ‰å…ƒç´ 
    


#### Â§ Series Â§

å¯ä½¿ç”¨`map()`èˆ‡`apply()`å…©ç¨®å‡½å¼ï¼Œå…©è€…åŠŸèƒ½å·®ä¸å¤šï¼Œéƒ½æ˜¯å°**Seriesç‰©ä»¶ä¸­çš„æ¯ä¸€å€‹å…ƒç´ å€¼**åšè™•ç†ï¼Œå·®åˆ¥åœ¨æ–¼`apply()`åƒ…èƒ½é€²è¡Œfunctiontè™•ç†ï¼Œè€Œ`map()`å¯ä»¥é€²è¡Œfunctionã€dictionaryã€Seriesè™•ç†

- `pd.Series(data, index=None)`ï¼šå»ºç«‹ä¸€å€‹Seriesç‰©ä»¶
    - dataï¼šè³‡æ–™å…§å®¹
    - indexï¼šæŒ‡æ¨™ï¼Œé è¨­ç‚ºæ•¸å­—
    
    ```python
    import pnadas as pd
    
    ser = pd.Series([1,2,3,4,5])
    ser
    #è¼¸å‡º
    0    1
    1    2
    2    3
    3    4
    4    5
    dtype: int64
    ```
    è‹¥æŒ‡å®šindex
    ```python
    ser = pd.Series([1,2,3,4,5], index=['one', 'two', 'three', 'four', 'five'])
    ser
    #è¼¸å‡º
    one      1
    two      2
    three    3
    four     4
    five     5
    dtype: int64
    ```

- é€²è¡Œfunctionè™•ç†ï¼šå°Seriesä¸­çš„æ¯å€‹å…ƒç´ ï¼Œ`apply()`èˆ‡`map()`çš†å¯ä½¿ç”¨
  > å…©è€…çµæœç›¸åŒ
   
   
   ```python
   ser.map(lambda x:x**2)
   #è¼¸å‡º
   0     1
   1     4
   2     9
   3    16
   4    25
   dtype: int64
    
    
   ser.apply(lambda x:x**2)
   #è¼¸å‡º
   0     1
   1     4
   2     9
   3    16
   4    25
   dtype: int64
   ```
    - `lambda x:y`ï¼šç°¡æ˜“çš„å®šç¾©å‡½å¼æ–¹æ³•
         - xï¼šinput
         - yï¼šoutput
   
   é™¤æ­¤ä¹‹å¤–ï¼Œ`apply()`é‚„å¯ä»¥æŒ‡å®šfunctionä¸­è¦å¸¶å…¥çš„åƒæ•¸
   > functioné ˆç‚º**å…©å€‹ä»¥ä¸Šåƒæ•¸**
   ```python
   def f(x, m):
       return x**m
    
   ser.apply(f, args=(3,))
   #è¼¸å‡º
   0      0
   1      8
   2    512
   3     64
   4    125
   dtype: int64
   ```
   > fç‚ºå…©å€‹åƒæ•¸çš„å‡½å¼ï¼š
   >  - ç¬¬ä¸€å€‹åƒæ•¸ï¼šSeriesä¸­çš„å„å€‹å…ƒç´ 
   >  - ç¬¬äºŒå€‹åƒæ•¸ï¼šargsä¸­æŒ‡å®š
   
   functionä¹Ÿå¯ä»¥å…©å€‹åƒæ•¸ä»¥ä¸Š
   ```python
   def f(x, m, a):
       return (x**m)+a

   ser.apply(f, args=(3,1))
   #è¼¸å‡º
   0      1
   1      9
   2    513
   3     65
   4    126
   dtype: int64
   ```   
      
   åŸ·è¡Œfunctioné›–ç„¶å…©è€…çµæœç›¸åŒï¼Œä½†è™•ç†éç¨‹ä¸åŒ
    - `apply()`ï¼šå°Seriesä¸­çš„å…ƒç´ åšå‡ºfunctionçš„æ‡‰ç”¨
    - `map()`ï¼š**å°‡åŸæœ¬çš„å€¼æ˜ å°„ï¼ˆmappingï¼‰åˆ°å¦ä¸€å€‹å€¼**
       > å› æ­¤`map()`ä¸åªå¯ä»¥æ¥æ”¶functionï¼Œé‚„å¯ä»¥æ¥æ”¶dictionaryã€Series
       
- é€²è¡Œdictionaryè™•ç†ï¼šå°‡Sericeä¸­çš„å…ƒç´ ä½œç‚ºdictä¸­çš„keysï¼Œä»¥æ­¤å°æ‡‰values
  > åƒ…é©ç”¨`map()`
  
  æœƒå°‡Seriesä¸­çš„å…ƒç´ ä½œç‚ºkeyå°æ‡‰åˆ°dictä¸­ï¼Œæ˜ å°„å‡ºç›¸å°æ‡‰çš„value
  ```python
  dic = {1:11, 2:21, 3:31, 5:51, 6:61}
  ser.map(dic)
  #è¼¸å‡º
  0    11.0
  1    21.0
  2    31.0
  3     NaN
  4    51.0
  dtype: float64
  ```
  > å°‡Seriesä¸­çš„å…ƒç´ ï¼Œç”±keyè½‰ç‚ºvalue
  >> å› ç‚ºdictä¸­ä¸å­˜åœ¨ã€Œ4ã€é€™å€‹keyï¼Œå› æ­¤è‡ªå‹•å¡«è£œã€ŒNaNã€
  
  
- é€²è¡ŒSeriesè™•ç†ï¼šå°‡Series_Aä¸­çš„å…ƒç´ ä½œç‚ºindexï¼Œå°æ‡‰åˆ°Series_Bä¸­çš„å…ƒç´ 
  > åƒ…é©ç”¨`map()`
  
    - Series_A.map(Series_B)
      > è‹¥Series_Aèˆ‡Series_Bä¸­å…ƒç´ ä¸ç›¸ç­‰ï¼Œä¸è¶³çš„æœƒè‡ªå‹•è£œä¸Šã€ŒNaNã€
  
  ```python
  ser_map = pd.Series(['A', 'B', 'C', 'D', 'E', 'F', 'G'])
  ser.map(ser_map)
  #è¼¸å‡º
  0    B
  1    C
  2    D
  3    E
  4    F
  dtype: object  
  ```
  > Series_B å…ƒç´ è¼ƒ Series_A å¤šï¼Œä½†å› Series_Aä¸­çš„å…ƒç´ å°æ‡‰å€¼å·²æ»¿è¶³ï¼Œå› æ­¤ä¸å½±éŸ¿
  
  
  ```python
  ser = pd.Series([0,2,8,4,5])
  ser.map(ser_map)
  #è¼¸å‡º
  0      A
  1      C
  2    NaN
  3      E
  4      F
  dtype: object
  ```
  > ç„¡æ³•å°æ‡‰å…ƒç´ ï¼Œè‡ªå‹•è£œä¸Šã€ŒNaNã€ 


#### Â§ DataFrame Â§

å¯ä»¥ä½¿ç”¨`apply()`èˆ‡`applymap()`
- `apply()`ï¼šä»¥columnç‚ºå–®ä½åšè¨ˆç®—
- `applymap()`ä»¥element-wiseè¨ˆç®—

   ```python
   df = pd.DataFrame([[1,2,3], [4,5,6], [7,8,9]])
   
   df.apply(sum)
   #è¼¸å‡º
   0    12
   1    15
   2    18
   dtype: int64
   ```
   > è¨ˆç®—æ¯colçš„ç¸½åˆ
   >> èˆ‡`df.sum()`ç›¸åŒ
   
   ä¹Ÿå¯è¨­å®šargs
   ```python
   def ff(xs, n):
       return xs.sum() *n
   
   df.apply(ff, args=(2,))
   #è¼¸å‡º
   0    24
   1    30
   2    36
   dtype: int64
   ```
   > å›  function ç‚º Aggregate functionsï¼Œæ‰€ä»¥å›å‚³ç‚ºSeries
    
   è‹¥ function ç‚º ufunc ï¼Œä¹Ÿå¯æœ‰ element-wise æ•ˆæœ
   ```python
   df.apply(lambda x:x-5)
   ```
   > å›å‚³ç‚ºdataframe
   
   ```python
   import numpy as np
   
   df.apply(np.sqrt)   
   ```
     - `np.sqrt`ï¼šå–å„å€‹å…ƒç´ çš„å¹³æ–¹æ ¹
   
#### Source
[pandasçš„mapã€applyã€applymap](https://home.gamer.com.tw/creationDetail.php?sn=4219422)

[SQL å‡½æ•°](https://www.w3school.com.cn/sql/sql_functions.asp)

[[Day10]Pandas Groupbyä½¿ç”¨ï¼](https://ithelp.ithome.com.tw/articles/10194027)

[pythonç§‘å­¦è®¡ç®—ä¹‹numpyâ€”â€”ufuncå‡½æ•°](https://blog.csdn.net/unixtch/article/details/78531585)

[ã€pythonã€‘numpyåº“ndarrayå¤šç»´æ•°ç»„çš„çš„è¿ç®—ï¼šnp.abs(x)ã€np.sqrt(x)ã€np.modf(x)ç­‰](https://blog.csdn.net/brucewong0516/article/details/79186176)

[ğŸ¦š](https://github.com/vanikk06/Machine-Learning/tree/master/Data#content)
